{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc39202",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01fc044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import math\n",
    "from xml.sax.saxutils import escape\n",
    "import re\n",
    "from typing import Dict, List\n",
    "from rasterio.windows import Window\n",
    "from rasterio.enums import Resampling\n",
    "import random\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.plot import show\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rioxarray.merge import merge_arrays\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from cdsapi import Client\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import openpyxl\n",
    "import rioxarray as rxr\n",
    "from ftplib import FTP\n",
    "import shutil\n",
    "import gc\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad76bcc4",
   "metadata": {},
   "source": [
    "## Data Folder Structure\n",
    "\n",
    "- data\n",
    "  - LANDSAT\n",
    "    - DAY\n",
    "      - LC08_L1TP_{PATH}{ROW}_{YYYMMDD}\n",
    "\n",
    "- Spatiotemporal\n",
    "  - Datetime: 2020/01/02 - 2020/02/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GDAL to use Py for Pixel Functions when calculating VRTs\n",
    "os.environ[\"GDAL_VRT_ENABLE_PYTHON\"] = \"YES\"\n",
    "\n",
    "# Defines the root path\n",
    "root = Path(\"data/LANDSAT\")\n",
    "\n",
    "# REGEX search for image bands with format: \"_B{bnum}\"\n",
    "band_re = re.compile(r\"_B(\\d{1,2})(?=(_|\\.))\", re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6dc56",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "\n",
    "_scene_id_from_name_ checks if a filename matches the REGEX band search (band_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe26cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scene_id_from_name(filename, debug = False):\n",
    "    m = band_re.search(filename)\n",
    "    if debug:\n",
    "        print(f\"Searching file: {filename}\")\n",
    "        if m:\n",
    "            print(f\"Found match with REGEX band search...\")\n",
    "            print(f\"Match = {m.group(0)} at position {m.start()}-{m.end()}\")\n",
    "        else:\n",
    "            print(f\"No match with REGEX band search found!\")\n",
    "    return filename[:m.start()] if m else filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152eed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples\n",
    "# 1. example showing one that works\n",
    "test_path = \"data/LANDSAT/DAY/LC08_L1TP_089083_20191106_20200825_02_T1/LC08_L1TP_089083_20191106_20200825_02_T1_B1.TIF\"\n",
    "scene_id_from_name(test_path, debug=True)\n",
    "\n",
    "# 2. example showing failure\n",
    "test_path = \"data/LANDSAT/DAY/LC08_L1TP_089083_20191106_20200825_02_T1/LC08_L1TP_089083_20191106_20200825_02_T1_SZA.TIF\"\n",
    "scene_id_from_name(test_path, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e624a1a",
   "metadata": {},
   "source": [
    "_collect_scenes_ searches the root data folder and finds matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_scenes(in_dir, debug = False):\n",
    "    scenes = {}\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Searching input directory \\\"{in_dir}\\\" for files that match REGEX band search...\")\n",
    "    for tif in in_dir.rglob(\"*.TIF\"):\n",
    "        m = band_re.search(tif.name)\n",
    "        if debug:\n",
    "            print(f'{tif.name}: {\"matched REGEX search for \" + m.group(0) if m else \"no match\"}')\n",
    "        if not m:\n",
    "            continue\n",
    "        b = int(m.group(1))\n",
    "        sid = scene_id_from_name(tif.name)\n",
    "        d = scenes.setdefault(sid, {})\n",
    "        # prefer shorter filename if duplicates exist\n",
    "        if b not in d or len(tif.name) < len(d[b].name):\n",
    "            d[b] = tif\n",
    "    return scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bc560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "scenes = collect_scenes(root, debug = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1c428",
   "metadata": {},
   "source": [
    "## TOA Radiance Derivation\n",
    "\n",
    "For bands B1-B11:\n",
    "\n",
    "$$L_{\\lambda} = M_L \\times Q_{cal} + A_L$$\n",
    "\n",
    "Where:\n",
    "- $L_{\\lambda}$ = spectral radiance (W/m^2 * sr * mircometers)\n",
    "- $M_L$ = radiance multiplicative scaling factor for the band (RADIANCE_MULT_BAND_n from metadata)\n",
    "- $A_L$ = radiance additive scaling factor for the for the band (RADIANCE_ADD_BAND_n from metadata)\n",
    "- $Q_{cal}$ = level-1 pixel value in DN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_bands = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c71d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RADIANCE scaling factors from metadata file (_MTL.txt)\n",
    "\n",
    "def get_rad_scaling_factors(mtl_path):\n",
    "    factors = {}\n",
    "    with open(mtl_path) as f:\n",
    "        for line in f:\n",
    "            if \"RADIANCE_MULT_BAND\" in line or \"RADIANCE_ADD_BAND\" in line:\n",
    "                key, val = line.strip().split(\" = \")\n",
    "                factors[key] = np.float32(val)\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define _RAD building VRT function\n",
    "def build_radiance_vrt(src_tif, M_lambda, A_lambda, in_dtype = \"UInt16\", out_dtype = \"Float32\", in_band = 1, out_band = 1, nodata_in=0, nodata_out=\"nan\"):\n",
    "    import rasterio\n",
    "\n",
    "    with rasterio.open(src_tif) as src:\n",
    "        w, h = src.width, src.height\n",
    "        transform = src.transform\n",
    "        crs_wkt = src.crs.to_wkt() if src.crs else \"\"\n",
    "\n",
    "    # Setup geotransform\n",
    "    gt = f\"{transform.c:.16g}, {transform.a:.16g}, {transform.b:.16g}, {transform.f:.16g}, {transform.d:.16g}, {transform.e:.16g}\"\n",
    "\n",
    "    # Load VRT template\n",
    "    xml = Path(\"templates/rad.xml\").read_text(encoding=\"utf-8\")\n",
    "\n",
    "    xml_mapping = {\n",
    "      \"width\": w,\n",
    "      \"height\": h,\n",
    "      \"crs_wkt\": escape(crs_wkt),\n",
    "      \"in_dtype\": in_dtype,\n",
    "      \"out_dtype\": out_dtype,\n",
    "      \"geo_transform\": gt,\n",
    "      \"in_band\": in_band,\n",
    "      \"out_band\": out_band,\n",
    "      \"src_filename\": escape(src_tif.name),\n",
    "      \"nodata_in\": nodata_in,\n",
    "      \"nodata_out\": nodata_out,\n",
    "      \"M_lambda\": f\"{M_lambda:.10g}\",\n",
    "      \"A_lambda\": f\"{A_lambda:.10g}\"\n",
    "    }\n",
    "\n",
    "    # Map values to keys in VRT template\n",
    "    for key, val in xml_mapping.items():\n",
    "      xml = xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "\n",
    "    # Output built VRT\n",
    "    out_vrt = src_tif.with_name(src_tif.stem + \"_RAD.vrt\")\n",
    "    out_vrt.write_text(xml, encoding=\"utf-8\")\n",
    "    return out_vrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddefa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop and build _RAD vrts\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = next(iter(bmap.values())).parent\n",
    "\n",
    "    print(f\"The input image is: {in_dir}\")\n",
    "\n",
    "    # Locate the MTL file\n",
    "    mtl_file = list(in_dir.glob(\"*_MTL.txt\"))\n",
    "\n",
    "    print(f\"The MTL file is: {mtl_file}\")\n",
    "    \n",
    "    if not mtl_file:\n",
    "        print(f\"No MTL found for {in_dir}\")\n",
    "\n",
    "    mtl_path = mtl_file[0]\n",
    "\n",
    "    # Read MTL scale factors\n",
    "    rad = get_rad_scaling_factors(mtl_path)\n",
    "\n",
    "    # Search bands for scale factors\n",
    "    for bnum in wanted_bands:\n",
    "        band = str(bnum)\n",
    "\n",
    "        src_tif = in_dir / f\"{sid}_B{band}.TIF\"\n",
    "        out_vrt = in_dir / f\"{sid}_B{band}_RAD.vrt\"\n",
    "\n",
    "        if not src_tif.exists():\n",
    "            print(f\"Skipping band {band}: {src_tif.name} not found\")\n",
    "            continue\n",
    "\n",
    "        M_lambda = rad.get(f\"RADIANCE_MULT_BAND_{band}\")\n",
    "        A_lambda = rad.get(f\"RADIANCE_ADD_BAND_{band}\")\n",
    "\n",
    "        print(f\"{out_vrt}: M_lambda={M_lambda}, A_lambda={A_lambda}\")\n",
    "\n",
    "        # Build VRT\n",
    "        print(\"Building VRT...\")\n",
    "        build_radiance_vrt(src_tif, M_lambda = M_lambda, A_lambda = A_lambda)\n",
    "        print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9430a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picks a random DN pixel from the source and calculates manually then compares to derived values\n",
    "test_src = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_B2.TIF\"\n",
    "test_rad = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_B2_RAD.vrt\"\n",
    "\n",
    "# From metadata MTL.text\n",
    "M_lambda = 0.013087\n",
    "A_lambda = -65.43689\n",
    "\n",
    "with rasterio.open(test_src) as src, rasterio.open(test_rad) as rad:\n",
    "    if (src.width != rad.width) or (src.height != rad.height):\n",
    "        raise ValueError(\"Source and derived VRT dimensions differ\")\n",
    "    \n",
    "    h, w = src.height, src.width\n",
    "\n",
    "    r = random.randrange(h)\n",
    "    c = random.randrange(w)\n",
    "\n",
    "    dn = src.read(1, window=((r, r+1), (c, c+1))).astype(np.float32)[0, 0]\n",
    "    rad_val = rad.read(1, window=((r, r+1), (c, c+1))).astype(np.float32)[0, 0]\n",
    "    \n",
    "    expected = M_lambda * dn + A_lambda\n",
    "\n",
    "    diff = expected - rad_val\n",
    "\n",
    "print(f\"The value in the source tif is: {dn}\")\n",
    "print(f\"The value in the derived vrt is: {rad_val}\")\n",
    "print(f\"The expected value is: {expected}\")\n",
    "print(f\"The difference is {diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd2a85",
   "metadata": {},
   "source": [
    "## TOA Reflectance Derivation (OLI)\n",
    "\n",
    "For bands B1-B9:\n",
    "\n",
    "$$\\rho_{\\lambda} = M_{\\rho} \\times Q_{cal} + A_{\\rho}$$\n",
    "\n",
    "Where:\n",
    "- $\\rho_{\\lambda}'$ = TOA Planetary Spectral Reflectance without correction for solar angle (unitless)\n",
    "- $M_{\\rho}$ = reflectance multiplicative factor for the band (REFLECTANCE_MULT_BAND_n from the metadata)\n",
    "- $A_{\\rho}$ = reflectance additive scaling factor for the band (REFLECTANCE_ADD_BAND_N)\n",
    "- $Q_{cal}$ = level 1 pixel DN value\n",
    "\n",
    "Correction for sun elevation:\n",
    "\n",
    "$$\\rho_{\\lambda}' = \\frac{\\rho_{\\lambda}}{\\sin{\\theta_{SE}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_bands = [1, 2, 3, 4, 5, 6, 7]\n",
    "root = Path(\"data/LANDSAT/DAY\") # Only need to do day\n",
    "scenes = collect_scenes(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376825ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reflectance factor\n",
    "def get_refl_scaling_factors(mtl_path):\n",
    "    factors = {}\n",
    "    with open(mtl_path) as f:\n",
    "        for line in f:\n",
    "            if \"REFLECTANCE_MULT_BAND\" in line or \"REFLECTANCE_ADD_BAND\" in line:\n",
    "                key, val = line.strip().split(\" = \")\n",
    "                factors[key] = np.float32(val)\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sun elevation factor\n",
    "def get_sun_elevation(mtl_path):\n",
    "    with open(mtl_path) as f:\n",
    "        for line in f:\n",
    "            if \"SUN_ELEVATION\" in line:\n",
    "                return float(line.strip().split(\" = \")[1])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c48fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define _REFL building function\n",
    "def build_reflectance_vrt(src_tif, M_rho, A_rho, sun_elev, in_dtype = \"UInt16\", out_dtype = \"Float32\", in_band = 1, out_band = 1, nodata_in=0, nodata_out=\"nan\"):\n",
    "\n",
    "    with rasterio.open(src_tif) as src:\n",
    "        width, height = src.width, src.height\n",
    "        transform = src.transform\n",
    "        crs_wkt = src.crs.to_wkt() if src.crs else \"\"\n",
    "\n",
    "    # Calculate angle-corrected REFL factors\n",
    "        s = math.sin(math.radians(sun_elev))\n",
    "        M_rho_prime = M_rho / s\n",
    "        A_rho_prime = A_rho / s\n",
    "\n",
    "    # Setup geotransform\n",
    "    gt = f\"{transform.c:.16g}, {transform.a:.16g}, {transform.b:.16g}, {transform.f:.16g}, {transform.d:.16g}, {transform.e:.16g}\"\n",
    "    \n",
    "\n",
    "    # Load VRT template\n",
    "    xml = Path(\"templates/refl.xml\").read_text(encoding=\"utf-8\")\n",
    "\n",
    "    xml_mapping = {\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"crs_wkt\": escape(crs_wkt),\n",
    "        \"in_dtype\": in_dtype,\n",
    "        \"out_dtype\": out_dtype,\n",
    "        \"geo_transform\": gt,\n",
    "        \"in_band\": in_band,\n",
    "        \"out_band\": out_band,\n",
    "        \"src_filename\": escape(src_tif.name),\n",
    "        \"nodata_in\": nodata_in,\n",
    "        \"nodata_out\": nodata_out,\n",
    "        \"M_rho\": f\"{M_rho_prime:.10g}\",\n",
    "        \"A_rho\": f\"{A_rho_prime:.10g}\",\n",
    "    }\n",
    "\n",
    "    # Map values to keys in VRT template\n",
    "    for key, val in xml_mapping.items():\n",
    "      xml = xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "\n",
    "    out_vrt = src_tif.with_name(src_tif.stem + \"_REFL.vrt\")\n",
    "    out_vrt.write_text(xml, encoding=\"utf-8\")\n",
    "    return out_vrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop and build VRTs\n",
    "\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = next(iter(bmap.values())).parent\n",
    "\n",
    "    print(f\"The input image is: {in_dir}\")\n",
    "\n",
    "    # Locate the MTL file\n",
    "    mtl_file = list(in_dir.glob(\"*_MTL.txt\"))\n",
    "\n",
    "    print(f\"The MTL file is: {mtl_file}\")\n",
    "    \n",
    "    if not mtl_file:\n",
    "        print(f\"No MTL found for {in_dir}\")\n",
    "\n",
    "    mtl_path = mtl_file[0]\n",
    "\n",
    "    # Read MTL scale factors\n",
    "    refl = get_refl_scaling_factors(mtl_path)\n",
    "    sun_elev = get_sun_elevation(mtl_path)\n",
    "\n",
    "    # Search bands for scale factors\n",
    "    for bnum in wanted_bands:\n",
    "        band = str(bnum)\n",
    "\n",
    "        src_tif = in_dir / f\"{sid}_B{band}.TIF\"\n",
    "        out_vrt = in_dir / f\"{sid}_B{band}_REFL.vrt\"\n",
    "\n",
    "        M_rho = refl.get(f\"REFLECTANCE_MULT_BAND_{band}\")\n",
    "        A_rho = refl.get(f\"REFLECTANCE_ADD_BAND_{band}\")\n",
    "\n",
    "        print(f\"{out_vrt}: M_rho={M_rho}, A_rho={A_rho}, SunElev={sun_elev}\")\n",
    "\n",
    "        # Build VRT\n",
    "        print(\"Building...\")\n",
    "        build_reflectance_vrt(src_tif, M_rho, A_rho, sun_elev=sun_elev)\n",
    "        print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8057204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picks a random DN pixel from the source and calculates manually then compares to derived values\n",
    "test_src = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_B2.TIF\"\n",
    "test_refl = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_B2_REFL.vrt\"\n",
    "\n",
    "# From metadata MTL.text\n",
    "M_rho = 2e-05\n",
    "A_rho = -0.1\n",
    "sun_elev = 59.45657641\n",
    "\n",
    "with rasterio.open(test_src) as src, rasterio.open(test_refl) as refl:\n",
    "    if (src.width != refl.width) or (src.height != refl.height):\n",
    "        raise ValueError(\"Source and derived VRT dimensions differ\")\n",
    "    \n",
    "    h, w = src.height, src.width\n",
    "\n",
    "    r = random.randrange(h)\n",
    "    c = random.randrange(w)\n",
    "\n",
    "    dn = src.read(1, window=((r, r+1), (c, c+1))).astype(np.float32)[0, 0]\n",
    "    refl_val = refl.read(1, window=((r, r+1), (c, c+1))).astype(np.float32)[0, 0]\n",
    "    \n",
    "    rho_lambda = M_rho * dn + A_rho\n",
    "    expected = rho_lambda / math.sin(math.radians(sun_elev))\n",
    "\n",
    "print(f\"The value in the source tif is: {dn}\")\n",
    "print(f\"The value in the derived vrt is: {refl_val}\")\n",
    "print(f\"The expected value is: {expected}\")\n",
    "print(f\"The difference is {diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03333b",
   "metadata": {},
   "source": [
    "## TOA Brightness Temperature (TIRS)\n",
    "\n",
    "For bands B11 and B12:\n",
    "\n",
    "$T = \\frac{K_2}{\\ln{\\frac{K_1}{L_{\\lambda}} + 1}}$\n",
    "\n",
    "Where:\n",
    "- $T$ = TOA Brightness Temp (K)\n",
    "- $L_{\\lambda}$ = TOA spectral radiance\n",
    "- $K_1$ = Band-specific thermal conversion constant from the metadata (K1_CONSTANT_BAND_x, where x is the thermal band number)\n",
    "- $K_2$ = Band-specific thermal conversion constant from the metadata (K2_CONSTANT_BAND_x, where x is the thermal band number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ff55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_bands = [10, 11]\n",
    "root = Path(\"data/LANDSAT\") # Do day and night\n",
    "scenes = collect_scenes(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a535aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get K constants for brightness temp\n",
    "def get_bt_factors(mtl_path):\n",
    "    factors = {}\n",
    "    with open(mtl_path) as f:\n",
    "        for line in f:\n",
    "            if \"K1_CONSTANT_BAND\" in line or \"K2_CONSTANT_BAND\" in line:\n",
    "                key, val = line.strip().split(\" = \")\n",
    "                factors[key] = np.float32(val)\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95936e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BT build VRT function\n",
    "def build_bt_vrt(src_tif, M_lambda, A_lambda, K1, K2, in_dtype = \"UInt16\", out_dtype = \"Float32\", in_band = 1, out_band = 1, nodata_in=0, nodata_out=-9999.0):\n",
    "\n",
    "    with rasterio.open(src_tif) as src:\n",
    "        width, height = src.width, src.height\n",
    "        transform = src.transform\n",
    "        crs_wkt = src.crs.to_wkt() if src.crs else \"\"\n",
    "\n",
    "    gt = f\"{transform.c:.16g}, {transform.a:.16g}, {transform.b:.16g}, {transform.f:.16g}, {transform.d:.16g}, {transform.e:.16g}\"\n",
    "\n",
    "    xml_mapping = {\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"crs_wkt\": escape(crs_wkt),\n",
    "        \"in_dtype\": in_dtype,\n",
    "        \"out_dtype\": out_dtype,\n",
    "        \"in_band\": in_band,\n",
    "        \"out_band\": out_band,\n",
    "        \"geo_transform\": gt,\n",
    "        \"src_filename\": escape(src_tif.name),\n",
    "        \"nodata_in\": nodata_in,\n",
    "        \"nodata_out\": nodata_out,\n",
    "        \"M_lambda\": M_lambda,\n",
    "        \"A_lambda\": A_lambda,\n",
    "        \"K1\": K1,\n",
    "        \"K2\": K2,\n",
    "    }\n",
    "\n",
    "    xml = Path(\"templates/bt.xml\").read_text(encoding = \"utf-8\")\n",
    "\n",
    "    for key, val in xml_mapping.items():\n",
    "      xml = xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "\n",
    "    out_vrt = src_tif.with_name(src_tif.stem + \"_BT.vrt\")\n",
    "    out_vrt.write_text(xml, encoding=\"utf-8\")\n",
    "    return out_vrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a68cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build BT VRTS\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = next(iter(bmap.values())).parent\n",
    "\n",
    "    print(f\"The input image is: {in_dir}\")\n",
    "\n",
    "    # Locate MTL file\n",
    "    mtl_file = list(in_dir.glob(\"*_MTL.txt\"))\n",
    "    \n",
    "    if not mtl_file:\n",
    "        print(f\"No MTL found for {in_dir}\")\n",
    "    \n",
    "    mtl_path = mtl_file[0]\n",
    "\n",
    "    # Read MTL scale factors / constants\n",
    "    rad = get_rad_scaling_factors(mtl_path)\n",
    "    bt = get_bt_factors(mtl_path)\n",
    "\n",
    "    # Search bands\n",
    "    for bnum in wanted_bands:\n",
    "        band = str(bnum)\n",
    "\n",
    "        src_tif = in_dir / f\"{sid}_B{band}.TIF\"\n",
    "        out_vrt = in_dir / f\"{sid}_B{band}_BT.vrt\"\n",
    "\n",
    "        M_lambda = rad.get(f\"RADIANCE_MULT_BAND_{band}\")\n",
    "        A_lambda = rad.get(f\"RADIANCE_ADD_BAND_{band}\")\n",
    "        K1     = bt.get(f\"K1_CONSTANT_BAND_{band}\")\n",
    "        K2     = bt.get(f\"K2_CONSTANT_BAND_{band}\")\n",
    "\n",
    "        if M_lambda is None or A_lambda is None or K1 is None or K2 is None:\n",
    "            print(f\"Missing M_lambda/A_lambda/K1/K2 for B{band}; skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"{out_vrt}: M_lambdaL = {M_lambda}, A_lambda={A_lambda}, K1={K1}, K2={K2}\")\n",
    "\n",
    "        print(f\"Building...\")\n",
    "        \n",
    "        build_bt_vrt(src_tif, M_lambda = M_lambda, A_lambda=A_lambda, K1 = K1, K2 = K2)\n",
    "\n",
    "        print(f\"Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12547152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picks a random DN pixel from the source and calculates manually then compares to derived values\n",
    "test_src = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_B10.TIF\"\n",
    "test_bt = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_B10_BT.vrt\"\n",
    "\n",
    "# From metadata MTL.text\n",
    "M_L = 3.3420E-04\n",
    "A_L = 0.10000\n",
    "K1 = 774.8853\n",
    "K2 = 1321.0789\n",
    "\n",
    "with rasterio.open(test_src) as src, rasterio.open(test_bt) as bt:\n",
    "    if (src.width != bt.width) or (src.height != bt.height):\n",
    "        raise ValueError(\"Source and derived VRT dimensions differ\")\n",
    "    \n",
    "    h, w = src.height, src.width\n",
    "\n",
    "    r = random.randrange(h)\n",
    "    c = random.randrange(w)\n",
    "\n",
    "    dn = src.read(1, window=((r, r+1), (c, c+1))).astype(np.float32)[0, 0] # Band 1 in tif\n",
    "    bt_val = bt.read(1, window=((r, r+1), (c, c+1))).astype(np.float32)[0, 0] # Band 3 in vrt\n",
    "    \n",
    "    L_lambda = M_L * dn + A_L\n",
    "    expected = K2 / math.log((K1 / L_lambda) + 1)\n",
    "\n",
    "    diff = expected - bt_val\n",
    "\n",
    "print(f\"The value in the source tif is: {dn}\")\n",
    "print(f\"The value in the derived vrt is: {bt_val}\")\n",
    "print(f\"The expected value is: {expected}\")\n",
    "print(f\"The difference is {diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda4ecb",
   "metadata": {},
   "source": [
    "# Night\n",
    "Clear:\n",
    "- LC08_L1GT_209161_20191217_20201023_02_T2\n",
    "- LC08_L1GT_209161_20191115_20200825_02_T2\n",
    "- LC08_L1GT_209160_20191217_20201023_02_T2\n",
    "- LC08_L1GT_208160_20191226_20200824_02_T2\n",
    "- LC08_L1GT_208161_20191226_20200824_02_T2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25abfb4",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "1. _RAD.vrts created for ALL bands\n",
    "2. _REFL.vrt created for OLI bands\n",
    "3. _BT.vrt created for TIRS bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22413b03",
   "metadata": {},
   "source": [
    "## Group single band _REFL.vrts into a multiband _TOA_REFL.vrt for each scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_bands = [2, 3, 4, 5, 6, 7]\n",
    "root = Path('data/LANDSAT/DAY') # Only do day\n",
    "scenes = collect_scenes(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f60d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_toa_refl_vrt(scene_id, bmap, out_vrt, refl_factors, sun_elev, wanted_bands, nodata_in = 0, nodata_out = \"nan\"):\n",
    "    # Reference band for georef\n",
    "    ref = bmap[min(bmap.keys())]\n",
    "\n",
    "    with rasterio.open(ref) as src:\n",
    "        w, h = src.width, src.height\n",
    "        transform = src.transform\n",
    "        crs_wkt = src.crs.to_wkt() if src.crs else \"\"\n",
    "    gt = f\"{transform.c:.16g}, {transform.a:.16g}, {transform.b:.16g}, {transform.f:.16g}, {transform.d:.16g}, {transform.e:.16g}\"\n",
    "\n",
    "    # Calculate sun elevation factor\n",
    "    s = math.sin(math.radians(sun_elev))\n",
    "\n",
    "    # Assemble per-band XML\n",
    "    bands_xml = []\n",
    "    out_idx = 1\n",
    "    for b in wanted_bands:\n",
    "        tif = bmap.get(b)\n",
    "        M_rho = refl_factors.get(f\"REFLECTANCE_MULT_BAND_{b}\")\n",
    "        A_rho = refl_factors.get(f\"REFLECTANCE_ADD_BAND_{b}\")\n",
    "\n",
    "        M_rho_prime = M_rho / s\n",
    "        A_rho_prime = A_rho / s\n",
    "\n",
    "        # Load VRT template\n",
    "        band_xml = Path(\"templates/band.xml\").read_text(encoding=\"utf-8\")\n",
    "\n",
    "        # Map variables to VRT template\n",
    "        band_xml_mapping = {\n",
    "            \"band_index\": out_idx,\n",
    "            \"nodata_in\": nodata_in,\n",
    "            \"nodata_out\": nodata_out,\n",
    "            \"source_filename\": escape(tif.name),\n",
    "            \"width\" : w,\n",
    "            \"height\": h,\n",
    "            \"out_idx\": out_idx,\n",
    "            \"scale_ratio\": f\"{M_rho_prime:.10g}\",\n",
    "            \"scale_offset\": f\"{A_rho_prime:.10g}\"\n",
    "        }\n",
    "        \n",
    "        for key, val in band_xml_mapping.items():\n",
    "            band_xml = band_xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "\n",
    "        bands_xml.append(band_xml)\n",
    "        out_idx += 1\n",
    "\n",
    "    # Load master template\n",
    "    master_xml = Path(\"templates/master.xml\").read_text(encoding = \"utf-8\")\n",
    "\n",
    "    # Add master components to .vrt XML\n",
    "    master_xml_mapping = {\n",
    "        \"width\": w,\n",
    "        \"height\": h,\n",
    "        \"crs_wkt\": escape(crs_wkt),\n",
    "        \"geo_transform\": gt,\n",
    "        \"mask_xml\": \"\",\n",
    "        \"bands_xml\": \"\\n\".join(bands_xml)\n",
    "    }\n",
    "\n",
    "    for key, val in master_xml_mapping.items():\n",
    "        master_xml = master_xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "    \n",
    "    out_vrt.write_text(master_xml, encoding=\"utf-8\")\n",
    "    print(\"→\", out_vrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccad6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through and construct a TOA_REFL vrt\n",
    "\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = bmap[min(bmap.keys())].parent\n",
    "    out_vrt = in_dir / f\"{sid}_TOA_REFL.vrt\"\n",
    "\n",
    "    # Locate MTL file\n",
    "    mtl_file = list(in_dir.glob(\"*_MTL.txt\"))\n",
    "\n",
    "    if not mtl_file:\n",
    "        print(f\"No MTL found for {in_dir}\")\n",
    "    \n",
    "    mtl_path = mtl_file[0]\n",
    "\n",
    "    # Read MTL scale factors\n",
    "    refl_factors = get_refl_scaling_factors(mtl_path)\n",
    "    sun_elev = get_sun_elevation(mtl_path)\n",
    "\n",
    "    build_toa_refl_vrt(scene_id=sid, bmap = bmap, out_vrt = out_vrt, refl_factors = refl_factors, sun_elev = sun_elev, wanted_bands = wanted_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a7f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify\n",
    "test_src = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_B4.TIF\" # Band 1 within the TIF\n",
    "test_toa = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_TOA_REFL.vrt\" # Band 3 within the VRT\n",
    "\n",
    "M_rho = 2.0000E-05\n",
    "A_rho = -0.1\n",
    "sun_elev = 59.45657641\n",
    "\n",
    "with rasterio.open(test_src) as src, rasterio.open(test_toa) as toa:\n",
    "    if (src.width != toa.width) or (src.height != toa.height):\n",
    "        raise ValueError(\"Source and derived VRT dimensions differ\")\n",
    "    \n",
    "    h, w = src.height, src.width\n",
    "\n",
    "    r = random.randrange(h)\n",
    "    c = random.randrange(w)\n",
    "\n",
    "    dn = src.read(1, window=((r, r+1), (c, c+1))).astype(np.float32)[0, 0] # Band 1 in tif\n",
    "    toa_val = toa.read(3, window=((r, r+1), (c, c+1))).astype(np.float32)[0, 0] # Band 3 in vrt\n",
    "    \n",
    "    rho = M_rho * dn + A_rho\n",
    "    rho_prime = rho / math.sin(math.radians(sun_elev))\n",
    "\n",
    "    diff = rho_prime - toa_val\n",
    "\n",
    "print(f\"The value in the source tif is: {dn}\")\n",
    "print(f\"The value in the derived vrt is: {toa_val}\")\n",
    "print(f\"The expected value is: {rho_prime}\")\n",
    "print(f\"The difference is {diff}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57cd401",
   "metadata": {},
   "source": [
    "## Valid Pixel Masking\n",
    "\n",
    "- Valid Pixel Masking should be performed before darkest object subtraction to make sure cloud shadows are not influencing the darkest object 1% quantile\n",
    "  - This is because a \"VALID\" darkest object is one that has intrinsically low reflectance, whereas cloud shadows are illumination artefact and can lead to overcorrection if included\n",
    "\n",
    "### Criteria\n",
    "- A common mask for Landsat 8 data is \"clear\" pixels:\n",
    "  - Fill = 0 <!-- i.e is not NoData fill -->\n",
    "  - Dilated cloud = 0\n",
    "  - Cirrus = 0\n",
    "  - Cloud = 0\n",
    "  - Ice/Snow = 0\n",
    "  - Cloud shadow = 0\n",
    "  - Clear = 1\n",
    "  - Cirrus conf < 1 <!-- Two-bit -->\n",
    "  - Cloud conf < 1 <!-- Two-bit -->\n",
    "  - Ice/snow conf < 1 <!-- Two-bit -->\n",
    "  - Cloud shadow conf <1 <!-- Two-bit -->\n",
    "\n",
    "\n",
    "### Sources\n",
    "- https://github.com/mapbox/rio-l8qa\n",
    "- “5.4 Unpacking Quality Assessment Band Bits” ([Zanter, 2016, p. 55](zotero://select/library/items/U5YN3SPF)) ([pdf](zotero://open-pdf/library/items/P2LF2YTN?page=63&annotation=TS5UTCRT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef0066",
   "metadata": {},
   "source": [
    "QA data for Landsat is encoded in bit flags. Some flags are single-bit (0 = No, 1 = Yes). Others are two-bit fields (0 = Not set, 1 = Low, 2 = Medium, 3 = High). \n",
    "\n",
    "_bit_reader_ extracts them by shifting the integer raster right by the starting bit position and masking off the relevant bits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adafae0",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81438600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_reader(x, b, two_bit = False):\n",
    "    if two_bit:\n",
    "        return ((x >> b) & 0b11).astype(np.uint8)\n",
    "    return((x >> b) & 1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4923051",
   "metadata": {},
   "source": [
    "NOTEs:\n",
    "- No need to construct a VRT since a QA alpha mask will apply across the whole scene / all bands, and will be relatively small filesize\n",
    "- Need to remove NaN padding for alpha mask..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c10620",
   "metadata": {},
   "source": [
    "### Build Mask TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ee3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_valid_mask(qa_pixel, out_tif, drop_water = False, debug = False):\n",
    "    with rasterio.open(qa_pixel) as qpix_src:\n",
    "        qpix = qpix_src.read(1).astype(np.uint16)\n",
    "        profile = qpix_src.profile\n",
    "\n",
    "    # Read QA bits\n",
    "    if debug:\n",
    "        print(\"Reading QA bits...\")\n",
    "    fill = bit_reader(qpix, 0) # Bit 0\n",
    "    dcloud = bit_reader(qpix, 1) # Bit 1 \n",
    "    cirrus = bit_reader(qpix, 2) # Bit 2\n",
    "    cloud  = bit_reader(qpix, 3) # Bit 3\n",
    "    shadow = bit_reader(qpix, 4) # Bit 4\n",
    "    snow   = bit_reader(qpix, 5) # Bit 5\n",
    "    clear = bit_reader(qpix, 6) # Bit 6\n",
    "    water = bit_reader(qpix, 7) # Bit 7\n",
    "    cloud_conf = bit_reader(qpix, 8, two_bit=True) # Bit 8-9\n",
    "    cloud_shadow_conf = bit_reader(qpix, 10, two_bit=True) # Bit 10-11\n",
    "    snow_conf = bit_reader(qpix, 12, two_bit=True) # Bit 12-13\n",
    "    cirrus_conf = bit_reader(qpix, 14, two_bit=True) # Bit 14-15\n",
    "\n",
    "    # Apply filters\n",
    "    if debug:\n",
    "        print(\"Applying filters for valid pixels...\")\n",
    "    valid = (\n",
    "        (fill == 0) & # 0 = Not fill\n",
    "        (dcloud == 0) & # 0 = No dilated cloud\n",
    "        (cloud == 0) & # 0 = No cloud\n",
    "        (shadow == 0) & # 0 = No cloud shadow\n",
    "        (cirrus == 0) & # 0 = No cirrus\n",
    "        (snow == 0) & # 0 = No snow\n",
    "        (cloud_conf <= 1) & # 0 = Not set, 1 = Low, 2 = Med, 3 = High\n",
    "        (cloud_shadow_conf <= 1) &\n",
    "        (snow_conf <= 1) &\n",
    "        (cirrus_conf <= 1)\n",
    "    )\n",
    "\n",
    "    # Optionally keep / drop water\n",
    "    if drop_water:\n",
    "        valid &= (water == 0)\n",
    "\n",
    "    if debug is True:\n",
    "        print(f\"The total number of pixels is: {valid.size}\")\n",
    "        print(f\"The toal number of clear pixels is {valid.sum()}\")\n",
    "        print(f\"The percentage of clear pixels is:\", float(valid.sum()) / float(valid.size) * 100, \"%\")\n",
    "\n",
    "    # Make alpha mask for valid\n",
    "    alpha = np.where(valid, 255, 0).astype(np.uint8)\n",
    "    \n",
    "    profile = profile.copy()\n",
    "    profile.update(\n",
    "        dtype = \"uint8\",\n",
    "        count = 1,\n",
    "    )\n",
    "\n",
    "    # Write alpha mask\n",
    "    with rasterio.open(out_tif, \"w\", **profile) as dest:\n",
    "        dest.write(alpha, 1)\n",
    "    if debug:\n",
    "        print(f\"Wrote alpha mask -> {out_tif}\")\n",
    "    \n",
    "    return valid, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c20751",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('data/LANDSAT')\n",
    "scenes = collect_scenes(root)\n",
    "\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = bmap[min(bmap.keys())].parent\n",
    "    qa_pixel = in_dir / f\"{sid}_QA_PIXEL.TIF\" \n",
    "    out_tif = in_dir / f\"{sid}_QA.TIF\"\n",
    "    build_valid_mask(qa_pixel = qa_pixel, out_tif = out_tif, drop_water = True, debug = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e9c464",
   "metadata": {},
   "source": [
    "## Surface Reflectance (OLI; Day)\n",
    "\n",
    "- Using Dark Object Subtraction (DOS)\n",
    "  - Simplest way to lessen effects of atmospheric scattering\n",
    "  - Procedure that gets the darkest pixel values and subtracts them from the rest\n",
    "  - Normalises images across time, allowing for the comparison of images under different atmospheric conditions\n",
    "\n",
    "$$\\rho_s = \\rho_{TOA} - \\rho_{haze}$$\n",
    "\n",
    "Where:\n",
    "- $\\rho_s$ = surface reflectance\n",
    "- $\\rho_{TOA}$ = TOA surface reflectance\n",
    "- $\\rho_{haze}$ = reflectance value of the darkest objects\n",
    "  - Generally slopes in complete shadow; sometimes deep water (though not sedimented water with high R/G reflectance!!)\n",
    "  - Can be the minimum value, or a percentile (should be less than 1%)\n",
    "\n",
    "\n",
    "[Chavez. 2014. *Re: What is the correct procedure for dark object subtraction?*](zotero://select/items/1_Y62JZNI9)\n",
    "\n",
    "[Chavez. 1996. *Image-Based Atmospheric Corrections - Revisited and Improved*](zotero://select/items/1_BJ4MIJXS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8dd2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.01 # dark object quantile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882918e7",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mask(m, debug = False):\n",
    "    if isinstance(m, np.ndarray):\n",
    "        out = m.astype(bool)\n",
    "    else:\n",
    "        with rasterio.open(m) as mask:\n",
    "            out = (mask.read(1) != 0)\n",
    "    if debug:\n",
    "        size = out.size\n",
    "        masked = int(out.sum())\n",
    "        print(f\"Masked {masked} ({masked/size*100:.2f}%) of {size} pixels\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dos_quantile(src, band_index, q = 0.01, mask = None, skip_zero = True, nodata = np.nan, debug = False):\n",
    "    if debug:\n",
    "        print(f\"Reading band {band_index} as float32\")\n",
    "    ds = src.read(band_index, out_dtype = \"float32\", masked = False)\n",
    "\n",
    "    if mask is not None:\n",
    "        if debug:\n",
    "            print(f\"Masking with {mask}\")\n",
    "        valid = load_mask(mask)\n",
    "        ds = np.where(valid, ds, np.nan)\n",
    "\n",
    "    v = ds.ravel()\n",
    "    \n",
    "    if skip_zero:\n",
    "        if debug:\n",
    "            n0 = np.count_nonzero(v == 0)\n",
    "            print(\"Skip_zero = true...\")\n",
    "            print(f\"Removing {n0} zeros\")\n",
    "        v = v[v != 0]\n",
    "\n",
    "    if not np.isnan(nodata):\n",
    "        if debug:\n",
    "            n_nd = np.count_nonzero(v == nodata)\n",
    "            print(f\"Nodata = {nodata}...\")\n",
    "            print(f\"Removing {n_nd} nodata matches\")\n",
    "        v = v[v != nodata]\n",
    "    \n",
    "    if debug:\n",
    "        n_nan = np.count_nonzero(~np.isfinite(v))\n",
    "        print(f\"Remove {n_nan} non-finite matches\")\n",
    "    v = v[np.isfinite(v)]\n",
    "    \n",
    "    if v.size == 0:\n",
    "        if debug:\n",
    "            print(\"No valid samples -> returning NaN\")\n",
    "        return np.nan\n",
    "    \n",
    "    out = float(np.quantile(v, q))\n",
    "    if debug:\n",
    "        print(f\"B{band}(q = {q}) = {out}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f4f4e",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627fe346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function with a known array\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "w, h = 5, 5\n",
    "test = np.arange(w*h, dtype=np.float32).reshape((h, w))\n",
    "test[1, 1] = 0.0\n",
    "\n",
    "test_mask = np.ones((h, w), dtype=np.uint8)\n",
    "test_mask[0:2, 0:2] = 0\n",
    "\n",
    "flat = test.ravel()\n",
    "expected_no_mask = float(np.quantile(flat[flat != 0], 0.2))\n",
    "\n",
    "masked = np.where(test_mask.astype(bool), test, np.nan)\n",
    "v = masked.ravel()\n",
    "v = v[v != 0]\n",
    "v = v[np.isfinite(v)]\n",
    "expected_mask = float(np.quantile(v, 0.2))\n",
    "\n",
    "transform = from_origin(0, 5, 1, 1)\n",
    "with MemoryFile() as memory_file:\n",
    "    with memory_file.open( driver= \"GTiff\", height = h, width = w, count = 1, dtype = \"float32\", transform = transform, crs = \"EPSG:4326\") as ds:\n",
    "        ds.write(test, 1)\n",
    "\n",
    "        r1 = dos_quantile(ds, 1, 0.2)\n",
    "        r2 = dos_quantile(ds, 1, 0.2, mask = test_mask)\n",
    "\n",
    "        d1 = abs(r1 - expected_no_mask)\n",
    "        d2 = abs(r2 - expected_mask)\n",
    "\n",
    "        print(f\"dos_quantile (no mask) got: {r1:.6g}, expected: {expected_no_mask:.6g}, diff: {d1:.3g}\")\n",
    "        print(f\"dos_quantile (w/ mask) got: {r2:.6g}, expected: {expected_mask:.6g}, diff: {d2:.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f30ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on Landsat data\n",
    "test_path = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_TOA_REFL.vrt\"\n",
    "test_mask = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_QA.TIF\"\n",
    "test_band = 3\n",
    "\n",
    "\n",
    "with rasterio.open(test_path) as ds:\n",
    "    q01 = dos_quantile(ds, band_index=test_band, q=0.01, mask=test_mask, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d14d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_haze_for_all_bands(src, q=0.01, mask = None, skip_zero = True, nodata = np.nan, debug = False):\n",
    "    haze_quantiles: list[float] = []\n",
    "    if debug:\n",
    "        print(f\"Opening {src} with rasterio...\")\n",
    "    with rasterio.open(src) as ds:\n",
    "        for b in range(1, ds.count +1):\n",
    "            if debug:\n",
    "                print(f\"Computing haze for {b}...\")\n",
    "            haze = dos_quantile(ds, band_index = b, q = q, mask = mask, skip_zero = skip_zero, nodata = nodata, debug = False)\n",
    "            haze = 0.0 if np.isnan(haze) else float(haze)\n",
    "            haze_quantiles.append(haze)\n",
    "            if debug:\n",
    "                print(f\"Haze is {haze}\")\n",
    "        return haze_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f047c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_TOA_REFL.vrt\"\n",
    "test_mask = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_QA.TIF\"\n",
    "\n",
    "compute_haze_for_all_bands(src = test_path, q=0.01, mask = test_mask, debug= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6d0c01",
   "metadata": {},
   "source": [
    "### Build SR VRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ca208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sr_vrt(src, haze_quantiles, out_vrt, mask = None, out_dtype = \"Float32\", nodata_in = \"0\", nodata_out = \"nan\"):\n",
    "    src = Path(src)\n",
    "    out_vrt = Path(out_vrt)\n",
    "    \n",
    "    with rasterio.open(src) as ds:\n",
    "        if len(haze_quantiles) != ds.count:\n",
    "            raise ValueError(f\"Number of haze-per-band values must match number of bands\")\n",
    "        \n",
    "        h, w = ds.height, ds.width\n",
    "        crs_wkt = ds.crs.to_wkt() if ds.crs else \"\"\n",
    "        transform = ds.transform\n",
    "\n",
    "    gt = f\"{transform.c:.16g}, {transform.a:.16g}, {transform.b:.16g}, {transform.f:.16g}, {transform.d:.16g}, {transform.e:.16g}\"\n",
    "    \n",
    "    if src.parent == out_vrt.parent:\n",
    "        src_filename = escape(src.name)\n",
    "        relative_to_vrt = \"1\"\n",
    "    else:\n",
    "        src_filename = escape(src.resolve().as_posix())\n",
    "        relative_to_vrt = \"0\"\n",
    "\n",
    "    bands_xml = []\n",
    "    for i, haze in enumerate(haze_quantiles, start = 1):\n",
    "    # Load VRT template\n",
    "        band_xml = Path(\"templates/sr_band.xml\").read_text(encoding=\"utf-8\")\n",
    "        # Map variables to VRT template\n",
    "        band_xml_mapping = {\n",
    "                \"band_index\": i,\n",
    "                \"source_band\": i,\n",
    "                \"src_filename\": src_filename,\n",
    "                \"relative_to_vrt\": relative_to_vrt,\n",
    "                \"nodata_out\": nodata_out,\n",
    "                \"nodata_in\": nodata_in,\n",
    "                \"out_dtype\": out_dtype,\n",
    "                \"width\": w,\n",
    "                \"height\": h,\n",
    "                \"scale_ratio\": \"1\",\n",
    "                \"scale_offset\": f\"{-float(haze):.10g}\",\n",
    "            }\n",
    "        \n",
    "        for key, val in band_xml_mapping.items():\n",
    "                band_xml = band_xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "        \n",
    "        bands_xml.append(band_xml)\n",
    "    \n",
    "    mask_xml = \"\"\n",
    "    if mask is not None:\n",
    "        mask = Path(mask)\n",
    "        if mask.parent == out_vrt.parent:\n",
    "            mask_src = escape(mask.name); mask_rel = \"1\"\n",
    "        else:\n",
    "            mask_src = escape(mask.resolve().as_posix()); mask_rel = \"0\"\n",
    "            # Load Mask VRT template\n",
    "        mask_xml = Path(\"templates/mask.xml\").read_text(encoding=\"utf-8\")\n",
    "        mask_xml = (\n",
    "            mask_xml\n",
    "            .replace(\"{{mask_src}}\", mask_src)\n",
    "            .replace(\"{{relative_to_vrt}}\", mask_rel)\n",
    "        )\n",
    "\n",
    "    # Add master components to .vrt XML\n",
    "    master_xml_mapping = {\n",
    "        \"width\": w,\n",
    "        \"height\": h,\n",
    "        \"crs_wkt\": escape(crs_wkt),\n",
    "        \"geo_transform\": gt,\n",
    "        \"mask_xml\": mask_xml,\n",
    "        \"bands_xml\": \"\\n\".join(bands_xml)\n",
    "    }\n",
    "\n",
    "    master_xml = Path(\"templates/master.xml\").read_text(encoding = \"utf-8\")\n",
    "    for key, val in master_xml_mapping.items():\n",
    "        master_xml = master_xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "    \n",
    "    out_vrt.write_text(master_xml, encoding=\"utf-8\")\n",
    "    print(\"->\", out_vrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively build SR vrts for each scene\n",
    "root = Path('data/LANDSAT/DAY')\n",
    "scenes = collect_scenes(root)\n",
    "\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = bmap[min(bmap.keys())].parent\n",
    "    toa_vrt = in_dir / f\"{sid}_TOA_REFL.vrt\"\n",
    "    mask = in_dir / f\"{sid}_QA.TIF\"\n",
    "    haze_quantiles = compute_haze_for_all_bands(src = toa_vrt, q = 0.01, mask = mask)\n",
    "    out_vrt = in_dir / f\"{sid}_SR.vrt\"\n",
    "    build_sr_vrt(src = toa_vrt, haze_quantiles = haze_quantiles, out_vrt = out_vrt, mask = mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70a9bb",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2b28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_toa = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_TOA_REFL.vrt\"\n",
    "test_sr = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_SR.vrt\"\n",
    "test_mask = \"data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_QA.TIF\"\n",
    "test_band = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "haze_quantiles = compute_haze_for_all_bands(src=test_toa, mask = test_mask, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bede4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The haze quantiles for each band, from the first on, are: {haze_quantiles}\")\n",
    "print(f\"The selected bands for TOA_REFL and SR are bands {test_band}\")\n",
    "print(f\"The darkest object subtraction quantile is: {haze_quantiles[test_band - 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a31f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly tests a derived SR pixel against an expected result\n",
    "with rasterio.open(test_toa) as toa, rasterio.open(test_sr) as sr:\n",
    "    assert toa.count == sr.count == len(haze_quantiles), f\"Band count mistmatch (TOA = {toa.count}, SR = {sr.count}, haze = {len(haze_quantiles)})\"\n",
    "    assert toa.width == sr.width and toa.height == sr.height, \"Dimension mismatch\"\n",
    "    assert toa.transform == sr.transform, \"Transform mismatch\"\n",
    "    assert toa.crs == sr.crs, \"CRS mismatch\"\n",
    "\n",
    "    h, w = toa.height, toa.width\n",
    "    \n",
    "    r = random.randrange(h)\n",
    "    c = random.randrange(w)\n",
    "\n",
    "    toa_val = toa.read(test_band, window=((r, r+1), (c, c+1))).astype(np.float32)[0, 0]\n",
    "    sr_val = sr.read(test_band, window=((r, r+1), (c, c+1))).astype(np.float32)[0, 0]\n",
    "\n",
    "    expected = toa_val - haze_quantiles[test_band - 1]\n",
    "\n",
    "    diff = expected - sr_val\n",
    "\n",
    "print(f\"The randomised test pixel is: {r} * {c}\")\n",
    "print(f\"The TOA_REFL value for this pixel is : {toa_val}\")\n",
    "print(f\"The SR value for this pixel is: {sr_val}\")\n",
    "print(f\"The expected SR value for this pixel is: {expected}\")\n",
    "print(f\"The difference between expected and returned is: {diff}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef10c24",
   "metadata": {},
   "source": [
    "### Checkpoint\n",
    "- SR VRTs\n",
    "  - Corrected with DOS\n",
    "  - Masked for cloud, snow, ice, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6974719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vrt_to_tif(vrt, out_path, debug = False):\n",
    "    with rasterio.open(vrt) as src:\n",
    "        \n",
    "        dtype = src.dtypes[0]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Source VRT is {dtype} datatype...\")\n",
    "            print(f\"Setting up metadata...\")\n",
    "        \n",
    "        profile = {\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"tiled\": True,\n",
    "            \"blockxsize\": 256,\n",
    "            \"blockysize\": 256,\n",
    "            \"height\": src.height,\n",
    "            \"width\": src.width,\n",
    "            \"count\": src.count,\n",
    "            \"dtype\": dtype,\n",
    "            \"crs\": src.crs,\n",
    "            \"transform\": src.transform,\n",
    "            \"compress\": \"lzw\",\n",
    "            \"nodata\": src.nodata\n",
    "        }\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Creating TIF...\")\n",
    "        with rasterio.open(out_path, \"w\", **profile) as dest:\n",
    "            if debug:\n",
    "                print(\"Transferring bands...\")\n",
    "            for i in range(1, src.count + 1):\n",
    "                if debug:\n",
    "                    print(f\"Writing data from band {i}...\")\n",
    "                data = src.read(i)\n",
    "                dest.write(data, i)\n",
    "\n",
    "            if debug:\n",
    "                print(\"Copying mask...\")\n",
    "            ds_mask = src.dataset_mask()\n",
    "            if ds_mask is not None:\n",
    "                dest.write_mask(ds_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792dc48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sid, bmap in sorted(scenes.items()):\n",
    "#     in_dir = bmap[min(bmap.keys())].parent\n",
    "#     sr_vrt = in_dir / f\"{sid}_SR.vrt\"\n",
    "#     out_path = in_dir / f\"{sid}_SR.tif\"\n",
    "#     vrt_to_tif(sr_vrt, out_path, debug = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ae1f2",
   "metadata": {},
   "source": [
    "## Compute NDVI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1a51a",
   "metadata": {},
   "source": [
    "According to the equation:\n",
    "\n",
    "$$ NDBI = \\frac{NIR - VIS_R}{NIR + VIS_R} $$\n",
    "\n",
    "NOTE: Bands 3 (Red) and 4 (NIR) in SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ndvi_vrt(src_sr, out_vrt, mask = None, out_band = 1, red_band = 3, nir_band = 4, out_dtype = \"Float32\", nodata_out = \"nan\", nodata_in = \"nan\"):\n",
    "    src_sr = Path(src_sr)\n",
    "    out_vrt = Path(out_vrt)\n",
    "\n",
    "    with rasterio.open(src_sr) as src:\n",
    "        w, h = src.width, src.height\n",
    "        crs_wkt = src.crs.to_wkt() if src.crs else \"\"\n",
    "        transform = src.transform\n",
    "\n",
    "    gt = f\"{transform.c:.16g}, {transform.a:.16g}, {transform.b:.16g}, {transform.f:.16g}, {transform.d:.16g}, {transform.e:.16g}\"\n",
    "\n",
    "    if src_sr.parent == out_vrt.parent:\n",
    "        src_filename = escape(src_sr.name)\n",
    "        relative_to_vrt = \"1\"\n",
    "    else:\n",
    "        src_filename = escape(src.resolve().as_posix())\n",
    "        relative_to_vrt = \"0\"\n",
    "\n",
    "    ndvi_xml = Path(\"templates/ndvi.xml\").read_text(encoding = \"utf-8\")\n",
    "\n",
    "    ndvi_mapping = {\n",
    "        \"width\": w,\n",
    "        \"height\": h,\n",
    "        \"out_dtype\": out_dtype,\n",
    "        \"out_band\": out_band,\n",
    "        \"crs_wkt\": escape(crs_wkt),\n",
    "        \"geo_transform\": gt,\n",
    "        \"nodata_out\": nodata_out,\n",
    "        \"nodata_in\": nodata_in,\n",
    "        \"nir_band\": nir_band,\n",
    "        \"red_band\": red_band,\n",
    "        \"relative_to_vrt\": relative_to_vrt,\n",
    "        \"src_filename\": src_filename,\n",
    "    }\n",
    "\n",
    "    for key, val in ndvi_mapping.items():\n",
    "        ndvi_xml = ndvi_xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "\n",
    "    mask_xml = \"\"\n",
    "    if mask is not None:\n",
    "        mask = Path(mask)\n",
    "        if mask.parent == out_vrt.parent:\n",
    "            mask_src = escape(mask.name); mask_rel = \"1\"\n",
    "        else:\n",
    "            mask_src = escape(mask.resolve().as_posix()); mask_rel = \"0\"\n",
    "            # Load Mask VRT template\n",
    "        mask_xml = Path(\"templates/mask.xml\").read_text(encoding=\"utf-8\")\n",
    "        mask_xml = (\n",
    "            mask_xml\n",
    "            .replace(\"{{mask_src}}\", mask_src)\n",
    "            .replace(\"{{relative_to_vrt}}\", mask_rel)\n",
    "        )\n",
    "\n",
    "    master_xml = Path(\"templates/master.xml\").read_text(encoding = \"utf-8\")\n",
    "\n",
    "    master_xml_mapping = {\n",
    "        \"width\": w,\n",
    "        \"height\": h,\n",
    "        \"crs_wkt\": escape(crs_wkt),\n",
    "        \"geo_transform\": gt,\n",
    "        \"mask_xml\": mask_xml,\n",
    "        \"bands_xml\": ndvi_xml\n",
    "    }\n",
    "\n",
    "    for key, val in master_xml_mapping.items():\n",
    "        master_xml = master_xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "\n",
    "    out_vrt.write_text(master_xml, encoding=\"utf-8\")\n",
    "    print(\"->\", out_vrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = bmap[min(bmap.keys())].parent\n",
    "    src_sr = in_dir / f\"{sid}_SR.vrt\"\n",
    "    out_vrt = in_dir / f\"{sid}_NDVI.vrt\"\n",
    "    mask = in_dir / f\"{sid}_QA.TIF\"\n",
    "    build_ndvi_vrt(src_sr= src_sr, out_vrt= out_vrt, mask = mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb07b1d9",
   "metadata": {},
   "source": [
    "## Compute NDBI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061efeed",
   "metadata": {},
   "source": [
    "According to the equation:\n",
    "\n",
    "$$ NDBI = \\frac{SWIR_1 - NIR}{SWIR_1 + NIR} $$\n",
    "\n",
    "NOTE: Band 4 (NIR) and Band 5 (SWIR) in SR  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948bc5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ndbi_vrt(src_sr, out_vrt, mask = None, out_band = 1, swir1_band = 5, nir_band = 4, out_dtype = \"Float32\", nodata_out = \"nan\", nodata_in = \"nan\"):\n",
    "    src_sr = Path(src_sr)\n",
    "    out_vrt = Path(out_vrt)\n",
    "\n",
    "    with rasterio.open(src_sr) as src:\n",
    "        w, h = src.width, src.height\n",
    "        crs_wkt = src.crs.to_wkt() if src.crs else \"\"\n",
    "        transform = src.transform\n",
    "\n",
    "    gt = f\"{transform.c:.16g}, {transform.a:.16g}, {transform.b:.16g}, {transform.f:.16g}, {transform.d:.16g}, {transform.e:.16g}\"\n",
    "\n",
    "    if src_sr.parent == out_vrt.parent:\n",
    "        src_filename = escape(src_sr.name)\n",
    "        relative_to_vrt = \"1\"\n",
    "    else:\n",
    "        src_filename = escape(src.resolve().as_posix())\n",
    "        relative_to_vrt = \"0\"\n",
    "\n",
    "    ndbi_xml = Path(\"templates/ndbi.xml\").read_text(encoding = \"utf-8\")\n",
    "\n",
    "    ndbi_mapping = {\n",
    "        \"width\": w,\n",
    "        \"height\": h,\n",
    "        \"out_dtype\": out_dtype,\n",
    "        \"out_band\": out_band,\n",
    "        \"crs_wkt\": escape(crs_wkt),\n",
    "        \"geo_transform\": gt,\n",
    "        \"nodata_out\": nodata_out,\n",
    "        \"nodata_in\": nodata_in,\n",
    "        \"nir_band\": nir_band,\n",
    "        \"swir1_band\": swir1_band,\n",
    "        \"relative_to_vrt\": relative_to_vrt,\n",
    "        \"src_filename\": src_filename,\n",
    "    }\n",
    "\n",
    "    for key, val in ndbi_mapping.items():\n",
    "        ndbi_xml = ndbi_xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "\n",
    "    mask_xml = \"\"\n",
    "    if mask is not None:\n",
    "        mask = Path(mask)\n",
    "        if mask.parent == out_vrt.parent:\n",
    "            mask_src = escape(mask.name); mask_rel = \"1\"\n",
    "        else:\n",
    "            mask_src = escape(mask.resolve().as_posix()); mask_rel = \"0\"\n",
    "            # Load Mask VRT template\n",
    "        mask_xml = Path(\"templates/mask.xml\").read_text(encoding=\"utf-8\")\n",
    "        mask_xml = (\n",
    "            mask_xml\n",
    "            .replace(\"{{mask_src}}\", mask_src)\n",
    "            .replace(\"{{relative_to_vrt}}\", mask_rel)\n",
    "        )\n",
    "\n",
    "    master_xml = Path(\"templates/master.xml\").read_text(encoding = \"utf-8\")\n",
    "\n",
    "    master_xml_mapping = {\n",
    "        \"width\": w,\n",
    "        \"height\": h,\n",
    "        \"crs_wkt\": escape(crs_wkt),\n",
    "        \"geo_transform\": gt,\n",
    "        \"mask_xml\": mask_xml,\n",
    "        \"bands_xml\": ndbi_xml\n",
    "    }\n",
    "\n",
    "    for key, val in master_xml_mapping.items():\n",
    "        master_xml = master_xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "\n",
    "    out_vrt.write_text(master_xml, encoding=\"utf-8\")\n",
    "    print(\"->\", out_vrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a5f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = bmap[min(bmap.keys())].parent\n",
    "    src_sr = in_dir / f\"{sid}_SR.vrt\"\n",
    "    out_vrt = in_dir / f\"{sid}_NDBI.vrt\"\n",
    "    mask = in_dir / f\"{sid}_QA.TIF\"\n",
    "    build_ndbi_vrt(src_sr= src_sr, out_vrt= out_vrt, mask = mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cfb34c",
   "metadata": {},
   "source": [
    "## Compute NDWI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504aeda9",
   "metadata": {},
   "source": [
    "According to the equation:\n",
    "\n",
    "$$ NDWI = \\frac{VIS_G - NIR}{VIS_G + NIR} $$\n",
    "\n",
    "NOTE: Band 2 (GREEN) and Band 4 (NIR) in SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d24512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ndwi_vrt(src_sr, out_vrt, mask = None, out_band = 1, green_band = 2, nir_band = 4, out_dtype = \"Float32\", nodata_out = \"nan\", nodata_in = \"nan\"):\n",
    "    src_sr = Path(src_sr)\n",
    "    out_vrt = Path(out_vrt)\n",
    "\n",
    "    with rasterio.open(src_sr) as src:\n",
    "        w, h = src.width, src.height\n",
    "        crs_wkt = src.crs.to_wkt() if src.crs else \"\"\n",
    "        transform = src.transform\n",
    "\n",
    "    gt = f\"{transform.c:.16g}, {transform.a:.16g}, {transform.b:.16g}, {transform.f:.16g}, {transform.d:.16g}, {transform.e:.16g}\"\n",
    "\n",
    "    if src_sr.parent == out_vrt.parent:\n",
    "        src_filename = escape(src_sr.name)\n",
    "        relative_to_vrt = \"1\"\n",
    "    else:\n",
    "        src_filename = escape(src.resolve().as_posix())\n",
    "        relative_to_vrt = \"0\"\n",
    "\n",
    "    ndwi_xml = Path(\"templates/ndwi.xml\").read_text(encoding = \"utf-8\")\n",
    "\n",
    "    ndwi_mapping = {\n",
    "        \"width\": w,\n",
    "        \"height\": h,\n",
    "        \"out_dtype\": out_dtype,\n",
    "        \"out_band\": out_band,\n",
    "        \"crs_wkt\": escape(crs_wkt),\n",
    "        \"geo_transform\": gt,\n",
    "        \"nodata_out\": nodata_out,\n",
    "        \"nodata_in\": nodata_in,\n",
    "        \"nir_band\": nir_band,\n",
    "        \"green_band\": green_band,\n",
    "        \"relative_to_vrt\": relative_to_vrt,\n",
    "        \"src_filename\": src_filename,\n",
    "    }\n",
    "\n",
    "    for key, val in ndwi_mapping.items():\n",
    "        ndwi_xml = ndwi_xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "\n",
    "    mask_xml = \"\"\n",
    "    if mask is not None:\n",
    "        mask = Path(mask)\n",
    "        if mask.parent == out_vrt.parent:\n",
    "            mask_src = escape(mask.name); mask_rel = \"1\"\n",
    "        else:\n",
    "            mask_src = escape(mask.resolve().as_posix()); mask_rel = \"0\"\n",
    "            # Load Mask VRT template\n",
    "        mask_xml = Path(\"templates/mask.xml\").read_text(encoding=\"utf-8\")\n",
    "        mask_xml = (\n",
    "            mask_xml\n",
    "            .replace(\"{{mask_src}}\", mask_src)\n",
    "            .replace(\"{{relative_to_vrt}}\", mask_rel)\n",
    "        )\n",
    "\n",
    "    master_xml = Path(\"templates/master.xml\").read_text(encoding = \"utf-8\")\n",
    "\n",
    "    master_xml_mapping = {\n",
    "        \"width\": w,\n",
    "        \"height\": h,\n",
    "        \"crs_wkt\": escape(crs_wkt),\n",
    "        \"geo_transform\": gt,\n",
    "        \"mask_xml\": mask_xml,\n",
    "        \"bands_xml\": ndwi_xml\n",
    "    }\n",
    "\n",
    "    for key, val in master_xml_mapping.items():\n",
    "        master_xml = master_xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "\n",
    "    out_vrt.write_text(master_xml, encoding=\"utf-8\")\n",
    "    print(\"->\", out_vrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e7e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = bmap[min(bmap.keys())].parent\n",
    "    src_sr = in_dir / f\"{sid}_SR.vrt\"\n",
    "    out_vrt = in_dir / f\"{sid}_NDWI.vrt\"\n",
    "    mask = in_dir / f\"{sid}_QA.TIF\"\n",
    "    build_ndwi_vrt(src_sr= src_sr, out_vrt= out_vrt, mask = mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d0f435",
   "metadata": {},
   "source": [
    "# Pixel-wise Emissivity ($\\epsilon$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7541086",
   "metadata": {},
   "source": [
    "Criteria from Wicki and Parlow [Wicki. 2017. *Multiple Regression Analysis for Unmixing of Surface Temperature Data in an Urban Environment*](zotero://select/items/1_2BRGFWGA)\n",
    "\n",
    "- $NDVI > 0.5 = 0.99$ ($NDVI_V$, $\\epsilon_V$) <!-- Veg -->\n",
    "- $NDWI > 0 = 0.98$ <!-- Water -->\n",
    "- $NDVI < 0.2 = 0.97$ ($NDVI_S$, $\\epsilon_S$) <!-- Soil -->\n",
    "- $NDBI > -0.2$ and $NDVI <0.35 = 0.9612$ <!-- Explicitly build areas -->\n",
    "- $0.2 < NDVI < 0.5$:\n",
    "\n",
    "$$\\epsilon = {\\epsilon}_{V}{P}_{V} + {\\epsilon}_{S}({1 - P_{V}}) + C$$\n",
    "\n",
    "$$P_{V} = \\bigl( {\\frac{NDVI - NDVI_S}{NDVI_V - NDVI_S}} \\bigr)^2$$\n",
    "\n",
    "$$C = (1 - {\\epsilon}_S){\\epsilon}_{V}{F'}(1-P_V)$$\n",
    "\n",
    "- $F'$ not automatically definable from optical or TIR data, therefore choose a mean value [(Sobrino. 2004. *Land surface temperature retrieval from LANDSAT TM 5*)](zotero://select/items/1_KPRGXQEK):\n",
    "\n",
    "$$F' = 0.55$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emissivity(\n",
    "    ndvi,\n",
    "    ndwi,\n",
    "    ndbi,\n",
    "    ndvi_v_threshold = 0.5,\n",
    "    ndvi_s_threshold = 0.2,\n",
    "    ndwi_threshold = 0,\n",
    "    ndbi_threshold = -0.2,\n",
    "    ndvi_b_threshold = 0.35,\n",
    "    eps_v = 0.99,\n",
    "    eps_s = 0.97,\n",
    "    eps_w = 0.98,\n",
    "    eps_b = 0.9612,\n",
    "    F_prime = 0.55,\n",
    "    out_dtype = \"float32\",\n",
    "    debug = False\n",
    "):\n",
    "    if debug:\n",
    "        print(\"Getting NDVI, NDWI, and NDBI values...\")\n",
    "    v = ndvi.values\n",
    "    w = ndwi.values\n",
    "    b = ndbi.values\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Initialising epsilon map...\")\n",
    "    eps = np.full(v.shape, np.nan, dtype = np.float32)\n",
    "\n",
    "    if debug:\n",
    "        print(\"Getting finite values for NDVI, NDWI and NDBI...\")\n",
    "    valid = np.isfinite(v)\n",
    "    valid &= np.isfinite(w)\n",
    "    valid &= np.isfinite(b)\n",
    "\n",
    "    # Create masks\n",
    "    if debug:\n",
    "        print(\"Creating masks for epsilon values...\")\n",
    "    \n",
    "    msk_water = (w >= ndwi_threshold)\n",
    "    if debug:\n",
    "        print(f\"Water mask: where NDWI >= {ndwi_threshold}\")\n",
    "\n",
    "    msk_veg = (v >= ndvi_v_threshold)\n",
    "    if debug:\n",
    "        print(f\"Dense veg mask: where NDVI >= {ndvi_v_threshold}\")\n",
    "\n",
    "    msk_soil = (v <= ndvi_s_threshold)\n",
    "    if debug:\n",
    "        print(f\"Soil mask: where NDVI <= {ndvi_s_threshold}\")\n",
    "\n",
    "    msk_built = (b > ndbi_threshold) & (v <= ndvi_b_threshold)\n",
    "    if debug:\n",
    "        print(f\"Built mask: where NDBI > {ndbi_threshold} and NDVI <= {ndvi_b_threshold}\")\n",
    "\n",
    "    # Apply epsilon to masks\n",
    "    if debug:\n",
    "        print(f\"Filling water mask with epsilon value: {eps_w}\")\n",
    "    eps[msk_water] = eps_w\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Filling dense veg mask with epsilon value: {eps_v}\")\n",
    "    eps[msk_veg & ~msk_water] = eps_v\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Filling built mask with epsilon value: {eps_b}\")\n",
    "    eps[msk_built & ~msk_veg & ~msk_water] = eps_b\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Filling soil mask with epsilon value: {eps_s}\")\n",
    "    eps[msk_soil & ~msk_veg & ~msk_water & ~msk_built] = eps_s\n",
    "\n",
    "    # Get unfilled and mixed pixels\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Finding unfilled values...\")\n",
    "    unfilled = np.isnan(eps)\n",
    "    \n",
    "    mix_range = (v > ndvi_s_threshold) & (v < ndvi_v_threshold)\n",
    "    msk_mix = unfilled & mix_range\n",
    "\n",
    "    # Calculate mixed pixels\n",
    "    if debug:\n",
    "        print(f\"Calculating mixed pixels according to emissivity equation...\")\n",
    "    if np.any(msk_mix):\n",
    "        numerator = (v - ndvi_s_threshold)\n",
    "        denominator = (ndvi_v_threshold - ndvi_s_threshold)\n",
    "        Pv = ( numerator / denominator) ** 2\n",
    "        C = (1.0 - eps_s) * eps_v * F_prime * (1.0 - Pv)\n",
    "        eps[msk_mix] = (eps_v * Pv[msk_mix]) + (eps_s * (1.0 - Pv[msk_mix])) + C[msk_mix]\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Exporting as an array...\")\n",
    "    eps = eps.astype(out_dtype)\n",
    "    return xr.DataArray(eps, dims=ndvi.dims, coords=ndvi.coords, name=\"emissivity\")\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test of the function\n",
    "\n",
    "v = np.array([[0.60, 0.10, 0.30], # Veg (0,0)\n",
    "              [0.40, 0.25, 0.49],\n",
    "              [0.00, 0.51, 0.20]], dtype=\"float32\")\n",
    "\n",
    "w = np.array([[-0.10, -0.20,  0.10], # Water (0,3)\n",
    "              [-0.50, -0.10, -0.20],\n",
    "              [ 0.20,  0.00, -0.30]], dtype=\"float32\") # Water (2,0) and (2,1)\n",
    "\n",
    "# Built > -0.2 & veg < 0.35\n",
    "b = np.array([[ 0.00, -0.10,  0.30],\n",
    "              [ 0.30,  0.50, -0.30],\n",
    "              [ 0.40, -0.10,  -0.50]], dtype=\"float32\")\n",
    "\n",
    "# Expecteds:\n",
    "# (0,0) = Veg\n",
    "# (0,1) = Built\n",
    "# (0,2) = Water\n",
    "# (1,0) = Mix\n",
    "# (1,1) = Built\n",
    "# (1,2) = Mix\n",
    "# (2,0) = Water\n",
    "# (2,1) = Water\n",
    "# (2,2) = Soil\n",
    "\n",
    "coords = {\"y\": np.arange(3), \"x\": np.arange(3)}\n",
    "NDVI = xr.DataArray(v, dims=(\"y\",\"x\"), coords=coords)\n",
    "NDWI = xr.DataArray(w, dims=(\"y\",\"x\"), coords=coords)\n",
    "NDBI = xr.DataArray(b, dims=(\"y\",\"x\"), coords=coords)\n",
    "\n",
    "E = emissivity(NDVI, NDWI, NDBI, debug = True)\n",
    "\n",
    "print(np.round(E.values, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_epsilon_vrt(ndvi_vrt, ndwi_vrt, ndbi_vrt, out_vrt, mask = None, out_dtype = \"Float32\", nodata_out = \"nan\", nodata_in = \"nan\"):\n",
    "    \n",
    "    with rasterio.open(ndvi_vrt) as ndvi:\n",
    "        w, h = ndvi.width, ndvi.height\n",
    "        crs_wkt = ndvi.crs.to_wkt() if ndvi.crs else \"\"\n",
    "        transform = ndvi.transform\n",
    "\n",
    "    gt = f\"{transform.c:.16g}, {transform.a:.16g}, {transform.b:.16g}, {transform.f:.16g}, {transform.d:.16g}, {transform.e:.16g}\"\n",
    "\n",
    "\n",
    "    metrics = {\n",
    "        \"NDVI\": Path(ndvi_vrt),\n",
    "        \"NDWI\": Path(ndwi_vrt),\n",
    "        \"NDBI\":Path(ndbi_vrt)\n",
    "    }\n",
    "\n",
    "    metric_filenames = {}\n",
    "    \n",
    "    for key, metric_src in metrics.items(): \n",
    "        if metric_src.parent == out_vrt.parent:\n",
    "            metric_filenames[key] = {\n",
    "                \"src_filename\": escape(metric_src.name),\n",
    "                \"relative_to_vrt\": \"1\",\n",
    "            }\n",
    "        else:\n",
    "            metric_filenames[key] = {\n",
    "                \"src_filename\": escape(metric_src.resolve().as_posix()),\n",
    "                \"relative_to_vrt\": \"0\"\n",
    "            }\n",
    "\n",
    "    epsilon_xml = Path(\"templates/epsilon.xml\").read_text(encoding = \"utf-8\")\n",
    "\n",
    "    epsilon_mapping = {\n",
    "        \"width\": w,\n",
    "        \"height\": h,\n",
    "        \"out_dtype\": out_dtype,\n",
    "        \"out_band\": 1,\n",
    "        \"nodata_out\": nodata_out,\n",
    "        \"nodata_in\": nodata_in,\n",
    "        \"NDVI_relative_to_vrt\": metric_filenames[\"NDVI\"][\"relative_to_vrt\"],\n",
    "        \"NDVI_src\": metric_filenames[\"NDVI\"][\"src_filename\"],\n",
    "        \"NDVI_band\": 1,\n",
    "        \"NDWI_relative_to_vrt\": metric_filenames[\"NDWI\"][\"relative_to_vrt\"],\n",
    "        \"NDWI_src\": metric_filenames[\"NDWI\"][\"src_filename\"],\n",
    "        \"NDWI_band\": 1,\n",
    "        \"NDBI_relative_to_vrt\": metric_filenames[\"NDBI\"][\"relative_to_vrt\"],\n",
    "        \"NDBI_src\": metric_filenames[\"NDBI\"][\"src_filename\"],\n",
    "        \"NDBI_band\": 1,\n",
    "    }\n",
    "\n",
    "    for key, val in epsilon_mapping.items():\n",
    "        epsilon_xml = epsilon_xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "\n",
    "    mask_xml = \"\"\n",
    "    if mask is not None:\n",
    "        mask = Path(mask)\n",
    "        if mask.parent == out_vrt.parent:\n",
    "            mask_src = escape(mask.name); mask_rel = \"1\"\n",
    "        else:\n",
    "            mask_src = escape(mask.resolve().as_posix()); mask_rel = \"0\"\n",
    "            # Load Mask VRT template\n",
    "        mask_xml = Path(\"templates/mask.xml\").read_text(encoding=\"utf-8\")\n",
    "        mask_xml = (\n",
    "            mask_xml\n",
    "            .replace(\"{{mask_src}}\", mask_src)\n",
    "            .replace(\"{{relative_to_vrt}}\", mask_rel)\n",
    "        )\n",
    "\n",
    "    master_xml = Path(\"templates/master.xml\").read_text(encoding = \"utf-8\")\n",
    "\n",
    "    master_xml_mapping = {\n",
    "        \"width\": w,\n",
    "        \"height\": h,\n",
    "        \"crs_wkt\": escape(crs_wkt),\n",
    "        \"geo_transform\": gt,\n",
    "        \"mask_xml\": mask_xml,\n",
    "        \"bands_xml\": epsilon_xml\n",
    "    }\n",
    "\n",
    "    for key, val in master_xml_mapping.items():\n",
    "        master_xml = master_xml.replace(f\"{{{{{key}}}}}\", str(val))\n",
    "\n",
    "    out_vrt.write_text(master_xml, encoding=\"utf-8\")\n",
    "    print(\"->\", out_vrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485dfd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('data/LANDSAT/DAY')\n",
    "scenes = collect_scenes(root)\n",
    "\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = bmap[min(bmap.keys())].parent\n",
    "    ndvi_vrt = in_dir / f\"{sid}_NDVI.vrt\"\n",
    "    ndwi_vrt = in_dir / f\"{sid}_NDWI.vrt\"\n",
    "    ndbi_vrt = in_dir / f\"{sid}_NDBI.vrt\"\n",
    "    mask = in_dir / f\"{sid}_QA.TIF\"\n",
    "    out_vrt = in_dir / f\"{sid}_E.vrt\"\n",
    "    build_epsilon_vrt(ndvi_vrt=ndvi_vrt, ndwi_vrt=ndwi_vrt, ndbi_vrt=ndbi_vrt, out_vrt=out_vrt, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"data/LANDSAT/DAY\")\n",
    "scenes = collect_scenes(root)\n",
    "\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = bmap[min(bmap.keys())].parent\n",
    "    sr_vrt = in_dir / f\"{sid}_E.vrt\"\n",
    "    out_path = Path(f\"out/DAY/{sid}_E.tif\")\n",
    "    vrt_to_tif(sr_vrt, out_path, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b4882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flushes the memory before dealing with big datasets\n",
    "for var in [\"da\", \"da_clip\", \"da_reproj\", \"da_list\", \"template\", \"aligned_da\", \"aligned\", \"stack\", \"median\"]:\n",
    "    if var in globals():\n",
    "        print(f\"Flushing {var}\")\n",
    "        del globals()[var]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db547390",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_crs = \"EPSG:3577\"\n",
    "in_dir = Path(\"out/DAY\")\n",
    "\n",
    "raster_files = sorted(in_dir.glob(\"*_E.tif\"))\n",
    "print(f\"{len(raster_files)} emissivity rasters\")\n",
    "\n",
    "aoi = gpd.read_file(\"bbox_sm.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_list = []\n",
    "\n",
    "for f in raster_files:\n",
    "    print(f\"Opening {f.name}\")\n",
    "    da = rxr.open_rasterio(f, masked = True, chunks = {\"x\":2048, \"y\":2048})\n",
    "\n",
    "    # Clip to AOI\n",
    "\n",
    "    aoi_src = aoi.to_crs(da.rio.crs)\n",
    "    da_clip = da.rio.clip(\n",
    "        aoi_src.geometry,\n",
    "        aoi_src.crs,\n",
    "        drop=True,\n",
    "    ).squeeze(\"band\", drop=True)\n",
    "\n",
    "    # Reproject\n",
    "    resx, resy = da_clip.rio.resolution()\n",
    "    da_reproj = da_clip.rio.reproject(\n",
    "        target_crs,\n",
    "        resolution=(resx, resy)\n",
    "    )\n",
    "\n",
    "    da_list.append(da_reproj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = merge_arrays(da_list)\n",
    "\n",
    "aligned = []\n",
    "for da in da_list:\n",
    "    aligned_da = da.rio.reproject_match(template)\n",
    "    aligned.append(aligned_da)\n",
    "\n",
    "stack = xr.concat(aligned, dim = \"time\")\n",
    "print(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = stack.median(\"time\", skipna = True).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"out/DAY/E_median_sm.tif\")\n",
    "median.rio.to_raster(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "out_path = Path('out/DAY/E_median_sm.tif')\n",
    "bbox_shp = \"bbox_sm.gpkg\"\n",
    "\n",
    "with rasterio.open(out_path) as src:\n",
    "    arr = src.read(1)\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    im = show(src, ax=ax, cmap='viridis')\n",
    "    cbar = fig.colorbar(im.get_images()[0], ax=ax)\n",
    "    plt.title(\"Emissivity (ε), Seasonal Average, Nov 2019-Jan 2020\")\n",
    "\n",
    "    bbox_gdf = gpd.read_file(bbox_shp)\n",
    "    if bbox_gdf.crs != src.crs:\n",
    "        bbox_gdf = bbox_gdf.to_crs(src.crs)\n",
    "    \n",
    "    bbox_gdf.boundary.plot(ax = ax, edgecolor= \"red\", linewidth = 2)\n",
    "\n",
    "    ax.annotate(\n",
    "        \"GDA94, EPSG:3577, Units: m\",\n",
    "        xy=(0.01, 0.01),\n",
    "        xycoords='axes fraction',\n",
    "        fontsize=6,\n",
    "        ha='left',\n",
    "        va='bottom',\n",
    "        bbox=dict(facecolor='white', alpha=0.0, edgecolor='none'),\n",
    "        zorder=1000\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "arr[arr == -9999] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c572ab",
   "metadata": {},
   "source": [
    "# Atmospheric Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8465ad6b",
   "metadata": {},
   "source": [
    "Wanted bands 10 [10600 - 11190], 11 [11500 - 12510]\n",
    "\n",
    "$$L_{\\lambda} = {\\tau}{\\epsilon}{L_T} + L_{u} + {\\tau}(1 - \\epsilon)L_{d}$$\n",
    "\n",
    "Where:\n",
    "- $L_T = $ surface-leaving radiance → ${B_i}{T_s}$\n",
    "- $\\tau = $ transmissivity\n",
    "- $L_u = $ upwelling/atmospheric path radiance\n",
    "- $L_d = $ downwelling/sky radiance\n",
    "- $L_{\\lambda} = $ TOA Radiance (as derived previously)\n",
    "- ${\\epsilon} = $ pixel-wise emissivity (as derived previously)\n",
    "\n",
    "Explanation:\n",
    "- To derive LST we need to solve the radiative transfer equation which is presented at the sensor above\n",
    "- To get the input parameters $\\tau$, $L_u$, $L_d$ we need to use an atmospheric correction model\n",
    "  - What we have derived so far is TOA values at the sensor\n",
    "    - To get surface values we need to correct for the atmosphere\n",
    "  - NASA's Atmospheric Correction Parameter Calculator was the standard for getting the parameters, but was shut down earlier this year\n",
    "    - Under the hood it used MODTRAN and NCEP atmospheric profiles to derive the parameters\n",
    "      - MODTRAN is paid software and too expensive for a student like me\n",
    "  - Instead we can use open-source libRadtran\n",
    "- Use libRadtran we need to input atmospheric profiles\n",
    "- We could use the standard \"midlat summer\" profile\n",
    "  - However these are essentially a mean for the whole summer period\n",
    "  - Since we are looking at day vs night, we'd be using the same atmospheric profile for both day and night scenes which would obviously be inaccurate\n",
    "- It would be better to get atmospheric profiles per-scene, matched to date and time\n",
    "  - We can do this with ERA5 or NCEP\n",
    "    - ERA5 has higher spatiotemporal resolution (1-hourly) and good global coverage, vs NCEP (6-hourly)\n",
    "      - Thus since we are trying to match specific day-night times ERA5 is the go\n",
    "- The parameters we need for libRadtran are:\n",
    "  - z(km), p(mb), T(K), air(cm-3), o3(cm-3), o2(cm-3), h2o(cm-3), co2(cm-3), no2(cm-3)\n",
    "  - We can derive what we need from ERA5 which gives pressure (p), temp (K), specific humidity (q), geopotential (z) and ozone mass mixing ratio (o3)\n",
    "  - We just have to assume ideal gas laws\n",
    "\n",
    "Steps:\n",
    "- Extract datetime of Landsat scene and match to ERA5 reanalysis\n",
    "- Build atmospheric profile per scene\n",
    "- Use atmospheric profile in libRadtran to get:\n",
    "  - edn\n",
    "  - upwelling\n",
    "  - transmissivity\n",
    "- Solve for L_d:\n",
    "  - $\\frac{edn}{\\pi}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddbab06",
   "metadata": {},
   "source": [
    "## Atmospheric Parameters Derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493cbafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('data/LANDSAT') # Do both day and night\n",
    "scenes = collect_scenes(root)\n",
    "\n",
    "wanted_bands = [10] # Only need band 10\n",
    "band_wavelengths = {\n",
    "    10: (10600, 11190), # See Landsat 8 user's guide\n",
    "    # 11: (11500, 12510)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c999562",
   "metadata": {},
   "source": [
    "### Build Atmospheric Profile per Landsat Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get Landsat spatiotemporal from the metadata MTL file\n",
    "\n",
    "def get_spacetime_params(mtl_path, buffer_deg = 0.0, debug = False):\n",
    "    target_keys = {\n",
    "        \"DATE_ACQUIRED\": None, # Acquisition date\n",
    "        \"SCENE_CENTER_TIME\": None, # Time passed over centre of scene\n",
    "        \"CORNER_UL_LAT_PRODUCT\": None, # upper left coords\n",
    "        \"CORNER_UL_LON_PRODUCT\": None,\n",
    "        \"CORNER_UR_LAT_PRODUCT\": None, # upper right coords\n",
    "        \"CORNER_UR_LON_PRODUCT\": None,\n",
    "        \"CORNER_LL_LAT_PRODUCT\": None, # lower left coords\n",
    "        \"CORNER_LL_LON_PRODUCT\": None,\n",
    "        \"CORNER_LR_LAT_PRODUCT\": None, # lower right coords\n",
    "        \"CORNER_LR_LON_PRODUCT\": None,\n",
    "    }\n",
    "\n",
    "    # Line parser\n",
    "    kv_re = re.compile(r'^\\s*([A-Z0-9_]+)\\s*=\\s*(.+?)\\s*$')\n",
    "\n",
    "    with open(mtl_path) as f:\n",
    "        for line in f:\n",
    "            m = kv_re.match(line)\n",
    "            if not m:\n",
    "                continue\n",
    "            key, val = m.group(1), m.group(2).strip()\n",
    "            if key not in target_keys:\n",
    "                continue\n",
    "            if len(val) >= 2 and val[0] in \"\\\"'\" and val[-1] == val[0]:\n",
    "                if debug:\n",
    "                    print(f\"Removing quotes around value: {val}\")\n",
    "                val = val[1:-1]\n",
    "            target_keys[key] = val\n",
    "\n",
    "    missing = [k for k, v in target_keys.items() if v is None]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required MTL keys: {missing}\")\n",
    "\n",
    "    if debug:\n",
    "        print(\"Parsed MTL keys:\")\n",
    "        for k, v in target_keys.items():\n",
    "            print(f\"    {k:25s} = {v}\")\n",
    "\n",
    "    # Get temporal params for ERA5\n",
    "    date = target_keys[\"DATE_ACQUIRED\"]\n",
    "    time = target_keys[\"SCENE_CENTER_TIME\"]\n",
    "    t_clean = time.strip().rstrip(\"Z\")\n",
    "\n",
    "    m = re.match(r\"(\\d{2}):(\\d{2})\", t_clean)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unrecognised time format: {time}\")\n",
    "    hour, minute = map(int, m.groups())\n",
    "    if debug:\n",
    "        print(f\"Stripping hour value = {hour} and minute value = {minute}\")\n",
    "\n",
    "    if minute >= 30:\n",
    "        hour += 1\n",
    "        if debug:\n",
    "            print(f\"Minute value > 30, rounding to nearest hour: {hour}\")\n",
    "    if hour == 24:\n",
    "        if debug:\n",
    "            print(f\"Hour value = 24, rolling over to 0\")\n",
    "        hour = 0\n",
    "        rollover = True\n",
    "    else:\n",
    "        rollover = False\n",
    "\n",
    "    if rollover:\n",
    "        if debug:\n",
    "            print(\"Rollover from 24:00 to 0:00 detected --> Modifying day by +1\")\n",
    "        date = (datetime.strptime(date, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Get spatial params for ERA5\n",
    "    lats = [\n",
    "        float(target_keys[\"CORNER_UL_LAT_PRODUCT\"]),\n",
    "        float(target_keys[\"CORNER_UR_LAT_PRODUCT\"]),\n",
    "        float(target_keys[\"CORNER_LL_LAT_PRODUCT\"]),\n",
    "        float(target_keys[\"CORNER_LR_LAT_PRODUCT\"]),\n",
    "    ]\n",
    "    lons = [\n",
    "        float(target_keys[\"CORNER_UL_LON_PRODUCT\"]),\n",
    "        float(target_keys[\"CORNER_UR_LON_PRODUCT\"]),\n",
    "        float(target_keys[\"CORNER_LL_LON_PRODUCT\"]),\n",
    "        float(target_keys[\"CORNER_LR_LON_PRODUCT\"]),\n",
    "    ]\n",
    "\n",
    "    north = max(lats) + buffer_deg\n",
    "    south = min(lats) - buffer_deg\n",
    "    west  = min(lons) - buffer_deg\n",
    "    east  = max(lons) + buffer_deg\n",
    "\n",
    "    if debug:\n",
    "        print(\"Extracting latitudes:\", lats)\n",
    "        print(\"Extracting longitudes:\", lons)\n",
    "        print(f\"Extracting bounding box (N, W, S, E): {north:.6f}, {west:.6f}, {south:.6f}, {east:.6f}\")\n",
    "\n",
    "    area = [north, west, south, east]\n",
    "\n",
    "    return date, hour, area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7322e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_era5(\n",
    "    date,\n",
    "    hour,\n",
    "    area,\n",
    "    out_path,\n",
    "    variables = None,\n",
    "    pressure_levels = None,\n",
    "    dataset = \"reanalysis-era5-pressure-levels\",\n",
    "    product_type = \"reanalysis\", fmt = \"netcdf\",\n",
    "    debug = False\n",
    "):\n",
    "\n",
    "    if variables is None:\n",
    "        variables = [\n",
    "            \"temperature\",\n",
    "            \"specific_humidity\",\n",
    "            \"geopotential\",\n",
    "            \"ozone_mass_mixing_ratio\"\n",
    "        ]\n",
    "        if debug:\n",
    "            print(\"No manual input; automatically choosing ERA5 variables\")\n",
    "    \n",
    "    if pressure_levels is None:\n",
    "        pressure_levels = [\n",
    "            \"1000\",\"975\",\"950\",\"925\",\"900\",\"875\",\"850\",\"825\",\"800\",\"775\",\n",
    "            \"750\",\"700\",\"650\",\"600\",\"550\",\"500\",\"450\",\"400\",\"350\",\"300\",\n",
    "            \"250\",\"225\",\"200\",\"175\",\"150\",\"125\",\"100\",\"70\",\"50\",\"30\",\"20\",\"10\"\n",
    "        ]\n",
    "        if debug:\n",
    "            print(\"No manual input; automatically choosing ERA5 pressure levels\")\n",
    "\n",
    "    year, month, day = date[:4], date[5:7], date[8:10]    \n",
    "    c = Client()\n",
    "    c.retrieve(\n",
    "        dataset,\n",
    "        {\n",
    "            \"product_type\": product_type,\n",
    "            \"format\": fmt,\n",
    "            \"variable\": variables,\n",
    "            \"pressure_level\": pressure_levels,\n",
    "            \"year\": year,\n",
    "            \"month\": month,\n",
    "            \"day\": day,\n",
    "            \"time\": hour,\n",
    "            \"area\": area,\n",
    "        },\n",
    "        out_path\n",
    "    )\n",
    "\n",
    "    print(f\"Downloaded atmospheric data to {out_path}\")\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcda6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_atm_prof(\n",
    "    era5_data,\n",
    "    area,\n",
    "    out_path,\n",
    "    show_stats = False,\n",
    "    debug = False\n",
    "):\n",
    "    # Constants\n",
    "    k_B = 1.380649e-23 # Boltzmann\n",
    "    N_A = 6.02214076e23 # Avogadro\n",
    "    g0 = 9.80665 # Gravitational constant\n",
    "    R_d = 287.05 # Dry air gas constant\n",
    "\n",
    "    # Molecular weights\n",
    "    m_air = 0.0289652\n",
    "    m_h2o = 0.01801528\n",
    "    m_o3 =  0.048\n",
    "    eps = m_h2o / m_air # ~0.622\n",
    "\n",
    "    chi_o2 =  0.20946 # 02 volume mixing ratio\n",
    "    chi_co2 = 420e-6 # C02 volume mixing ratio, approximately 420 ppm for modern scenes\n",
    "    chi_no2 = 0.5e-9 # Small placeholder\n",
    "\n",
    "    if debug:\n",
    "        print(\"Loading ERA5 data...\")\n",
    "        print(\"Slicing to the appropriate area...\")\n",
    "    ds = xr.load_dataset(era5_data)\n",
    "\n",
    "    # Subset by area again to only get the data full within (i.e not edge / overlappers)\n",
    "    ds_subset = ds.sel(latitude=slice(area[0], area[2]), longitude=slice(area[1], area[3]))\n",
    "\n",
    "    if show_stats:\n",
    "        for var in ds_subset.data_vars:\n",
    "            v = ds_subset[var]\n",
    "            print(f\"\\nVariable: {var}\")\n",
    "            print(f\"  min:  {float(v.min().values):.4g}\")\n",
    "            print(f\"  max:  {float(v.max().values):.4g}\")\n",
    "            print(f\"  mean: {float(v.mean().values):.4g}\")\n",
    "            print(f\"  std:  {float(v.std().values):.4g}\")\n",
    "\n",
    "    if debug:\n",
    "        print(\"Calculating median atmospheric profile...\")\n",
    "    median = ds_subset.median(dim = [\"latitude\", \"longitude\"], skipna = True, keep_attrs=True)\n",
    "\n",
    "    # Strip the time dimension so that we can build the dataframe later on (and its not needed)\n",
    "    median = median.mean(dim = \"valid_time\", skipna=True)\n",
    "    median = median.sortby(\"pressure_level\")\n",
    "\n",
    "    p_hPa = median[\"pressure_level\"].values.astype(float)\n",
    "    p_Pa = p_hPa * 100\n",
    "    T = median[\"t\"].values\n",
    "    q = median[\"q\"].values\n",
    "    phi = median[\"z\"].values\n",
    "    mmro3 = median[\"o3\"].values\n",
    "\n",
    "    # Height derivation\n",
    "    z_m = phi / g0\n",
    "    z_km = z_m / 1000.0\n",
    "\n",
    "    # Air number density derivation\n",
    "    n_air_m3 = p_Pa / (k_B * T)\n",
    "    air_cm3 = n_air_m3 / 1e6\n",
    "\n",
    "    # Water vapour number density derivation\n",
    "    r = q / (1.0 - q)\n",
    "    e = p_Pa * r / (r + eps)\n",
    "    n_h2o_m3 = e / (k_B * T)\n",
    "    h2o_cm3  = n_h2o_m3 / 1e6\n",
    "\n",
    "    # Ozone number density derivation\n",
    "    R_m      = R_d * (1 + r/eps) / (1 + r)\n",
    "    rho_air  = p_Pa / (R_m * T)\n",
    "    conc_O3  = mmro3 * rho_air\n",
    "    mol_O3   = conc_O3 / m_o3\n",
    "    n_O3_m3  = mol_O3 * N_A\n",
    "    o3_cm3   = n_O3_m3 / 1e6\n",
    "\n",
    "    # O2 and CO2 number density derivation\n",
    "    o2_cm3   = chi_o2  * air_cm3\n",
    "    co2_cm3  = chi_co2 * air_cm3\n",
    "\n",
    "    # NO2 number density derivation\n",
    "    no2_cm3  = chi_no2 * air_cm3\n",
    "\n",
    "    atm_profile = pd.DataFrame({\n",
    "        \"z(km)\"     : z_km,\n",
    "        \"p(mb)\"     : p_hPa, # 1 mb = 1hPa\n",
    "        \"T(K)\"      : T,\n",
    "        \"air(cm-3)\" : air_cm3,\n",
    "        \"o3(cm-3)\"  : o3_cm3,\n",
    "        #\"o2(cm-3)\"  : o2_cm3,\n",
    "        \"h2o(cm-3)\" : h2o_cm3,\n",
    "        #\"co2(cm-3)\" : co2_cm3,\n",
    "        #\"no2(cm-3)\" : no2_cm3,\n",
    "    })\n",
    "\n",
    "    atm_profile = atm_profile.sort_values(\"z(km)\", ascending = False).reset_index(drop=True) # libRadtran expects descending order\n",
    "    \n",
    "    # Need to manually insert commented header lines for libRadtran compatability\n",
    "    header_lines = [\n",
    "        \"# \" + \" \".join(atm_profile.columns),\n",
    "    ]\n",
    "\n",
    "    if debug:\n",
    "        print(\"Saving atmospheric profile to .dat\")\n",
    "\n",
    "    with open(out_path, \"w\", newline=\"\\n\") as f:\n",
    "        for line in header_lines:\n",
    "            f.write(line + \"\\n\")\n",
    "        atm_profile.to_csv(\n",
    "            f,\n",
    "            sep=\" \",\n",
    "            index = False,\n",
    "            header = False,\n",
    "            float_format = \"%.6e\",\n",
    "            lineterminator = \"\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d7987",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = next(iter(bmap.values())).parent\n",
    "    era5_out_path = in_dir / f\"{sid}_ATM.nc\"\n",
    "    atm_prof_out_path = in_dir / f\"{sid}_ATM_PROF.dat\"\n",
    "    print(f\"The input image is: {in_dir}\")\n",
    "\n",
    "    # Locate MTL file\n",
    "    mtl_file = list(in_dir.glob(\"*_MTL.txt\"))\n",
    "    \n",
    "    if not mtl_file:\n",
    "        print(f\"No MTL found for {in_dir}\")\n",
    "    \n",
    "    mtl_path = mtl_file[0]\n",
    "\n",
    "    # Extract spatiotemporal characteristics\n",
    "    date, hour, area = get_spacetime_params(mtl_path, debug = True)\n",
    "\n",
    "    # Download ERA5 data\n",
    "    era5_data = retrieve_era5(date, hour, area, out_path = era5_out_path, debug = True)\n",
    "\n",
    "    # Constructure median atmospheric profile for the Landsat scene\n",
    "    atm_profile = build_atm_prof(era5_data, area, out_path = atm_prof_out_path, debug = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce9384",
   "metadata": {},
   "source": [
    "- The ERA5 data has been downloaded\n",
    "- The next function builds the atmospheric profile\n",
    "- Since the ERA5 dataset has a 30 km resolution, I extract a median atmospheric profile\n",
    "  - This will be fine since we're looking to derive the approximate from the at-sensor RTE equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f8d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_ld(\n",
    "    mnt,\n",
    "    uvspec_path,\n",
    "    atmosphere_input,\n",
    "    ld_inp,\n",
    "    ld_out,\n",
    "    lambda_min,\n",
    "    lambda_max,\n",
    "    source = \"thermal\",\n",
    "    azimuth = 0,\n",
    "    umu = 1.0,\n",
    "    z = 0,\n",
    "    debug = False,\n",
    "):\n",
    "\n",
    "    # Handle POSIX paths\n",
    "\n",
    "    print(atmosphere_input)\n",
    "    print(ld_inp)\n",
    "\n",
    "    mounted_atmosphere_input = mnt / atmosphere_input\n",
    "    posix_atm_prof = mounted_atmosphere_input.as_posix()\n",
    "    if debug:\n",
    "        print(posix_atm_prof)\n",
    "\n",
    "    mounted_ld_inp = mnt / ld_inp\n",
    "    posix_ld_inp = mounted_ld_inp.as_posix()\n",
    "    if debug:\n",
    "        print(posix_ld_inp)\n",
    "\n",
    "    mounted_ld_out = mnt / ld_out\n",
    "    posix_ld_out = mounted_ld_out.as_posix()\n",
    "    if debug:\n",
    "        print(posix_ld_out)\n",
    "\n",
    "    # Create ld input file\n",
    "\n",
    "    params = {\n",
    "        \"SOURCE\": source,\n",
    "        \"ATM_PROF\": posix_atm_prof,\n",
    "        \"UMU\": umu,\n",
    "        \"NM_MIN\": lambda_min,\n",
    "        \"NM_MAX\": lambda_max,\n",
    "        \"AZIMUTH\": azimuth,\n",
    "        \"Z\": z,\n",
    "    }\n",
    "\n",
    "    ld_template = 'libradtran/templates/l_d.INP'\n",
    "\n",
    "    with open(ld_template, \"r\") as f:\n",
    "        template = f.read()\n",
    "    \n",
    "    filled = template.format(**params)\n",
    "\n",
    "    with open(ld_inp, \"w\") as f:\n",
    "        f.write(filled)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Deriving ld...\") \n",
    "        print(f\"Sending command: {uvspec_path} < {posix_ld_inp} > {posix_ld_out}\")\n",
    "    \n",
    "    cmd = (\n",
    "        f\"cd /home/samla/libRadtran-2.0.6/bin && \"\n",
    "        f\"./uvspec < {posix_ld_inp} > {posix_ld_out}\"\n",
    "        )\n",
    "    \n",
    "    subprocess.run([\"wsl\", \"bash\", \"-lc\", cmd], check = True)\n",
    "\n",
    "    # Post process\n",
    "    df = pd.read_csv(ld_out, sep=r\"\\s+\", header = None)\n",
    "    df.columns = [\"wavelength_nm\", \"L_d\"]\n",
    "    df.to_csv(ld_out, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9660db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnt = '/mnt/c/Users/samla/Desktop/temp/GEOM7001_A1/GEOM7001_A1' # mount point for WSL to access Windows\n",
    "uvspec_path =  '/home/samla/libRadtran-2.0.6/bin/uvspec'\n",
    "\n",
    "\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "\n",
    "    in_dir = next(iter(bmap.values())).parent\n",
    "    \n",
    "    atmosphere_input = in_dir / f\"{sid}_ATM_PROF.dat\"\n",
    "    \n",
    "    for band in wanted_bands:\n",
    "        lambda_min, lambda_max = band_wavelengths[band]\n",
    "\n",
    "        ld_inp = in_dir / f\"{sid}_B{band}_LD.inp\"\n",
    "        ld_out = in_dir / f\"{sid}_B{band}_LD.dat\"\n",
    "\n",
    "        # Derive ld for the scene\n",
    "        derive_ld(\n",
    "            mnt = mnt,\n",
    "            uvspec_path = uvspec_path,\n",
    "            atmosphere_input = atmosphere_input,\n",
    "            ld_inp = ld_inp,\n",
    "            ld_out = ld_out,\n",
    "            lambda_min = lambda_min,\n",
    "            lambda_max = lambda_max,\n",
    "            debug = True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_lu(\n",
    "    mnt,\n",
    "    uvspec_path,\n",
    "    atmosphere_input,\n",
    "    lu_inp,\n",
    "    lu_out,\n",
    "    lambda_min,\n",
    "    lambda_max,\n",
    "    source = 'thermal',\n",
    "    umu = 1.0,\n",
    "    azimuth = 0,\n",
    "    z = 'TOA',\n",
    "    debug = False,\n",
    "):\n",
    "\n",
    "    # Handle POSIX paths\n",
    "\n",
    "    print(atmosphere_input)\n",
    "    print(lu_inp)\n",
    "\n",
    "    mounted_atmosphere_input = mnt / atmosphere_input\n",
    "    posix_atm_prof = mounted_atmosphere_input.as_posix()\n",
    "    if debug:\n",
    "        print(posix_atm_prof)\n",
    "\n",
    "    mounted_lu_inp = mnt / lu_inp\n",
    "    posix_lu_inp = mounted_lu_inp.as_posix()\n",
    "    if debug:\n",
    "        print(posix_lu_inp)\n",
    "\n",
    "    mounted_lu_out = mnt / lu_out\n",
    "    posix_lu_out = mounted_lu_out.as_posix()\n",
    "    if debug:\n",
    "        print(posix_lu_out)\n",
    "\n",
    "    # Create lu input file\n",
    "\n",
    "    params = {\n",
    "        \"SOURCE\": source,\n",
    "        \"ATM_PROF\": posix_atm_prof,\n",
    "        \"UMU\": umu,\n",
    "        \"AZIMUTH\": azimuth,\n",
    "        \"NM_MIN\": lambda_min,\n",
    "        \"NM_MAX\": lambda_max,\n",
    "        \"Z\": z,\n",
    "    }\n",
    "\n",
    "    lu_template = 'libradtran/templates/l_u.INP'\n",
    "\n",
    "    with open(lu_template, \"r\") as f:\n",
    "        template = f.read()\n",
    "    \n",
    "    filled = template.format(**params)\n",
    "\n",
    "    with open(lu_inp, \"w\") as f:\n",
    "        f.write(filled)\n",
    "\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Deriving lu...\") \n",
    "        print(f\"Sending command: {uvspec_path} < {posix_lu_inp} > {posix_lu_out}\")\n",
    "    \n",
    "    cmd = (\n",
    "        f\"cd /home/samla/libRadtran-2.0.6/bin && \"\n",
    "        f\"./uvspec < {posix_lu_inp} > {posix_lu_out}\"\n",
    "    )\n",
    "\n",
    "    subprocess.run([\"wsl\", \"bash\", \"-lc\", cmd], check = True)\n",
    "\n",
    "    # Post process\n",
    "    df = pd.read_csv(lu_out, sep=r\"\\s+\", header = None)\n",
    "    df.columns = [\"wavelength_nm\", \"L_u\"]\n",
    "    df.to_csv(lu_out, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b5b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnt = '/mnt/c/Users/samla/Desktop/temp/GEOM7001_A1/GEOM7001_A1' # mount point for WSL to access Windows\n",
    "uvspec_path =  '/home/samla/libRadtran-2.0.6/bin/uvspec'\n",
    "\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "\n",
    "    in_dir = next(iter(bmap.values())).parent\n",
    "    \n",
    "    atmosphere_input = in_dir / f\"{sid}_ATM_PROF.dat\"\n",
    "    \n",
    "    for band in wanted_bands:\n",
    "        lambda_min, lambda_max = band_wavelengths[band]\n",
    "\n",
    "        lu_inp = in_dir / f\"{sid}_B{band}_LU.inp\"\n",
    "        lu_out = in_dir / f\"{sid}_B{band}_LU.dat\"\n",
    "\n",
    "        # Derive lu for the scene\n",
    "        derive_lu(\n",
    "            mnt = mnt,\n",
    "            uvspec_path = uvspec_path,\n",
    "            atmosphere_input = atmosphere_input,\n",
    "            lu_inp = lu_inp,\n",
    "            lu_out = lu_out,\n",
    "            lambda_min = lambda_min,\n",
    "            lambda_max = lambda_max,\n",
    "            debug = True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bc9ba",
   "metadata": {},
   "source": [
    "# Spectral Response (SRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bad6cd",
   "metadata": {},
   "source": [
    "- Our simulation of the atmosphere does not include the sensor properties which imperfectly captures radiance\n",
    "- We need to correct for the sensor using the spectral response, which is essentially how the sensor captures radiance at different\n",
    "- Additionally $L_d$ and $L_u$ are given by our atmospheric simulation over a range of wavelengths for each band\n",
    "- The conversion to LST requires that we compress these, so we need to take a band average \n",
    "- After this section we should end up with a band-average $L_u$ and $L_d$ that has been weighted for the sensor spectral response for each band\n",
    "\n",
    "$$\n",
    "\\lambda_i\n",
    "=\n",
    "\\frac{\n",
    "\\displaystyle \\int_{\\lambda_{1,i}}^{\\lambda_{2,i}} f_i(\\lambda)\\,\\lambda\\, d\\lambda\n",
    "}{\n",
    "\\displaystyle \\int_{\\lambda_{1,i}}^{\\lambda_{2,i}} f_i(\\lambda)\\, d\\lambda\n",
    "} $$\n",
    "\n",
    "- This equation gives us the effective / representative wavelength for the band "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert it to csv to make everything easier to manage\n",
    "xlsx_path = 'tirs_srs.xlsx'\n",
    "csv_path = 'tirs_srs.csv'\n",
    "\n",
    "# Cleaning\n",
    "df = pd.read_excel(xlsx_path)\n",
    "df = df.loc[:, ~df.columns.str.contains(r\"^Unnamed\")]\n",
    "df = df.drop(columns=[\"Relative to RADIANCE\"])\n",
    "df[\"wavelength [um]\"] = df[\"wavelength [um]\"] * 1000.0\n",
    "\n",
    "rename_map = {\n",
    "    \"wavelength [um]\": \"wavelength_nm\",\n",
    "    \"TIRS1 10.8um band average\": \"srf_b10\",\n",
    "    \"TIRS2 12.0um band average\": \"srf_b11\",\n",
    "    \"stdev(TIRS1 all dets) [%]\": \"stdev_b10\",\n",
    "    \"stdev(TIRS2 all dets) [%]\": \"stdev_b11\"\n",
    "}\n",
    "\n",
    "df = df.rename(columns = rename_map)\n",
    "df.to_csv(csv_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def effective_band_wavelength(\n",
    "    srf_input,\n",
    "    band,\n",
    "    lambda_col = \"wavelength_nm\"\n",
    "):\n",
    "    srf_band_col = f\"srf_b{band}\"\n",
    "    srf_df = pd.read_csv(srf_input)\n",
    "    lambda_srf = srf_df[lambda_col].to_numpy(dtype=float)\n",
    "    r = srf_df[srf_band_col].to_numpy(dtype=float)\n",
    "\n",
    "    num = np.trapz(r * lambda_srf, lambda_srf)\n",
    "    den = np.trapz(r, lambda_srf)\n",
    "\n",
    "    if den == 0:\n",
    "        raise ValueError(\"SRF integral is zero, check the input\")\n",
    "\n",
    "    effective_band_wavelength = num / den\n",
    "\n",
    "    return effective_band_wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9224e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = effective_band_wavelength(\n",
    "    srf_input = 'tirs_srs.csv',\n",
    "    band = 10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35fa8c3",
   "metadata": {},
   "source": [
    "# Radiance Aggregation\n",
    "- The downwelling ($L_d$) and upwelling ($L_u$) radiance components outputted by libRadtran do not have a spatial dimension because they are derived from the atmospheric profile which is scene-level\n",
    "- They do have a spectral resolution however, meaning that we have L_d and L_u per micrometer (!!) of wavelength\n",
    "  - Thus we aggregate these because each Landsat band incorporates a range of wavelengths\n",
    "- It's not as simple as getting a median or average, because the sensor reacts differently to different wavelengths; this is known as the sensor's spectral response (SRF)\n",
    "  - Thus we need to get radiance values that are aggregated for SRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rad_srf_weighter(\n",
    "    ld_input,\n",
    "    lu_input,\n",
    "    srf_input,\n",
    "    band,\n",
    "    lambda_col = \"wavelength_nm\", # I standardised the names across l_d, l_u and srf datasets\n",
    "    ld_col = 'L_d',\n",
    "    lu_col = 'L_u',\n",
    "):\n",
    "\n",
    "    srf_band_col = f\"srf_b{band}\"\n",
    "\n",
    "    # Load srf\n",
    "    srf_df = pd.read_csv(srf_input)\n",
    "    lamda_srf = srf_df[lambda_col]\n",
    "    r = srf_df[srf_band_col].to_numpy(dtype=float)\n",
    "\n",
    "    # Load ld and lu for the band\n",
    "    def load(\n",
    "        path,\n",
    "        val_col\n",
    "    ):\n",
    "        df = pd.read_csv(path)\n",
    "        df = df[[lambda_col, val_col]].dropna().sort_values(lambda_col)\n",
    "        lam = df[lambda_col].to_numpy(dtype=float)\n",
    "        val = df[val_col].to_numpy(dtype=float)\n",
    "        return lam, val\n",
    "    \n",
    "    lamda_ld, ld_val = load(ld_input, ld_col)\n",
    "    lamda_lu, lu_val = load(lu_input, lu_col)\n",
    "\n",
    "    # Interpolate\n",
    "\n",
    "    ld_interp = np.interp(lamda_srf, lamda_ld, ld_val)\n",
    "    lu_interp = np.interp(lamda_srf, lamda_lu, lu_val)\n",
    "\n",
    "    # Band average\n",
    "    num_ld = np.trapz(ld_interp * r, lamda_srf)\n",
    "    num_lu = np.trapz(lu_interp * r, lamda_srf)\n",
    "    den = np.trapz(r, lamda_srf)\n",
    "\n",
    "    ld_band_average = num_ld / den \n",
    "    lu_band_average = num_lu / den\n",
    "\n",
    "    return ld_band_average, lu_band_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ld = 'data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_B10_LD.dat'\n",
    "test_lu = 'data\\LANDSAT\\DAY\\LC08_L1TP_089083_20191106_20200825_02_T1\\LC08_L1TP_089083_20191106_20200825_02_T1_B10_LU.dat'\n",
    "test_srf = 'tirs_srs.csv'\n",
    "test_band = 10\n",
    "\n",
    "ld10, lu10 = rad_srf_weighter(\n",
    "    ld_input = test_ld,\n",
    "    lu_input = test_lu,\n",
    "    srf_input = test_srf,\n",
    "    band = test_band\n",
    ")\n",
    "\n",
    "print(f\"The outputted SRF-weighted band-average value for L_d and L_u is: L_d = {ld10}; L_d = {lu10} [W/m^2/sr/nm]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "h  = 6.62607015e-34   # Planck constant [J*s]\n",
    "c  = 2.99792458e8     # Speed of light [m/s]\n",
    "kB = 1.380649e-23     # Boltzmann constant [J/K]\n",
    "\n",
    "def planck(wavelength_um, temperature_K):\n",
    "    lam_m = wavelength_um * 1e-6  # µm → m\n",
    "    c1 = 2 * h * c**2\n",
    "    c2 = h * c / kB\n",
    "    B_m = (c1 / lam_m**5) / (np.exp(c2 / (lam_m * temperature_K)) - 1)  # W/(m^2 sr m)\n",
    "    return B_m * 1e-6  # → W/(m^2 sr µm)\n",
    "\n",
    "def planck_inverse(wavelength_um, radiance):\n",
    "    lam_m = wavelength_um * 1e-6  # µm → m\n",
    "    c1 = 2 * h * c**2\n",
    "    c2 = h * c / kB\n",
    "\n",
    "    # Convert radiance to per-metre units for the formula\n",
    "    L_m = radiance * 1e6  # W/(m^2 sr m)\n",
    "\n",
    "    # T = c2 / (λ * ln(1 + c1 / (L λ^5)))\n",
    "    return c2 / (lam_m * np.log(1.0 + c1 / (L_m * lam_m**5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737880b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blackbody test - We're testing our simulation of the atmosphere and the outputted parameters of the radiative transfer equation\n",
    "# We assume the object under our atmosphere is a blackbody with full absorption (i.e emissivity = 1) with a \"known\" temperature of 300K\n",
    "# The radiance that would be reaching our Landsat 8 sensor is ~13.3\n",
    "\n",
    "K = 300 # Test temp\n",
    "lam = 11.0 # About the middle of Band 10\n",
    "e = 1 # Full absorption by the blackbody\n",
    "tau = 0.9 # About normal for clear sky conditions\n",
    "ld = ld10 * 1000 # Convert to um\n",
    "lu = lu10 * 1000 # Convert to um\n",
    "\n",
    "print(f\"The downwelling radiation component is: {ld} [W/m^2/sr/um]\")\n",
    "print(f\"The upwelling radiation component is: {lu} [W/m^2/sr/um]\")\n",
    "\n",
    "test = tau * (e * planck(lam, K) + (1 - e) * ld) + lu\n",
    "\n",
    "print(f\"The radiance reaching the sensor is: {test} [W/m^2/sr/um]\")\n",
    "\n",
    "# Quickly test the inverse Planck fx\n",
    "\n",
    "L_toa = test\n",
    "B_surface = (L_toa - lu) / tau\n",
    "T_recover = planck_inverse(lam, B_surface)\n",
    "print(f\"Inverting Planck's law allows us to recover the temperature: {T_recover} K\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa1393",
   "metadata": {},
   "source": [
    "# Transmissivity ($\\tau$)\n",
    "\n",
    "- Can be estimated from water content ($w$) (g/cm^2) / precipitable water ($PW$) ($kg/m^2$) available in the atmospheric profile:\n",
    "\n",
    "$$PW = \\frac{1}{g}\\int{q}{dp}$$\n",
    "\n",
    "Where:\n",
    "- ${g} = $ gravity\n",
    "- ${q} = $ specific humidity\n",
    "- ${p} = $ pressure\n",
    "\n",
    "For mid latitude summer $\\tau$ is a quadratic relationship with coefficients that vary depending on the Landsat 8 band (https://www.mdpi.com/2072-4292/6/10/9829):\n",
    "| Atmosphere Profile | Water Content Range (w) | Equation                                                                                        |\n",
    "| ------------------ | ----------------------- | ----------------------------------------------------------------------------------------------- |\n",
    "| Midlat Summer      | $0.2-3.0$               | $\\tau_{B10} = −0.0164w^2 − 0.04203w + 0.9715$ <br> $\\tau_{B11} = −0.01218w^2 − 0.07735w + 0.9603$ |\n",
    "|                    | $3.0-6.0$               | $\\tau_{B10} = −0.00168w^2 − 0.1329w + 1.127$ <br> $\\tau_{B11} = −0.09186w^2 − 0.2137w + 1.181$    |\n",
    "\n",
    "For these relationships: $R^2$ $> 0.999$, RMSE $< 0.003$\n",
    "\n",
    "NOTE: These are specific to Landsat 8/9 TIRS and thus do not need to be band-averaged (weighted for SRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b440ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_water_content(\n",
    "    era5_input,\n",
    "    q_var = 'q',\n",
    "    p_coord = 'pressure_level',\n",
    "    vertical_dimension = 'pressure_level',\n",
    "    debug = False\n",
    "):\n",
    "    # Constants\n",
    "    g = 9.80665\n",
    "    if debug:\n",
    "        print(f\"Set gravitational constant: {g}\")\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Opening inputted ERA5 dataset...\")\n",
    "    ds = xr.open_dataset(era5_input)\n",
    "    q = ds[q_var]\n",
    "    p = ds[p_coord]\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Converting hPa to Pa\")\n",
    "    p_pa = p * 100 # mb/hPa -> Pa\n",
    "\n",
    "    # Sort by pressure\n",
    "    if debug:\n",
    "        print(f\"Sorting values by pressure...\")\n",
    "    q = q.sortby(p_pa)\n",
    "    p_pa = p_pa.sortby(p_pa)\n",
    "\n",
    "    # Compute PW using trapezoidal rule along vertical dimension\n",
    "    axis = q.get_axis_num(vertical_dimension)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Solving the precipitable water (PW) equation: (1/g) ∫ q dp...\")\n",
    "    pw_vals = np.trapz(q.values, p_pa.values, axis=axis) / g\n",
    "\n",
    "    # Build result\n",
    "    if debug:\n",
    "        print(f\"Building output...\")\n",
    "    out_dims = [d for d in q.dims if d != vertical_dimension]\n",
    "    out_coords = {k: v for k, v in q.coords.items() if k != vertical_dimension}\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Building precipitable water (PW) array...\")\n",
    "    pw = xr.DataArray(\n",
    "        pw_vals,\n",
    "        dims = out_dims,\n",
    "        coords = out_coords,\n",
    "        name = \"PW\",\n",
    "        attrs = {\n",
    "            \"long_name\" : \"Precipitable Water\",\n",
    "            \"units\": \"kg m-2\",\n",
    "            \"formula\": \"PW = (1/g) ∫ q dp\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Building water content (w) array...\")\n",
    "    w = pw * 0.1\n",
    "    w.name = \"w\"\n",
    "    w.attrs.update(\n",
    "        {\n",
    "            \"long_name\": \"Water content\",\n",
    "            \"units\": \"g cm-2\",\n",
    "            \"note\": \"w = 0.1 * PW\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return pw, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4bfc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def derive_tau(\n",
    "#     w,\n",
    "#     band,\n",
    "#     debug = False\n",
    "# ):\n",
    "#     w_valid = w.where((w>= 0.2) & (w<= 6.0))\n",
    "\n",
    "#     c = 0.944228\n",
    "#     b = -0.052720\n",
    "#     a = -0.011912\n",
    "\n",
    "#     tau = a * w_valid ** 2 + b * w_valid + c\n",
    "\n",
    "#     return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_tau(\n",
    "    w,\n",
    "    band,\n",
    "    debug = False\n",
    "):\n",
    "    if debug:\n",
    "        print(f\"Checking inputted band for compatibility...\")\n",
    "    if band not in (10, 11):\n",
    "        raise ValueError(\"Only bands 10 or 11 are supported for this derivation\")\n",
    "    else:\n",
    "        if debug:\n",
    "            print(f\"Band compatible!\")\n",
    "\n",
    "    # Coefficients for the tau polynomial(s) per band (see Yu et al, 2014)\n",
    "\n",
    "    coeff_map = {\n",
    "        10: {\n",
    "            \"low\":  {\"a\": -0.0164,  \"b\": -0.04203, \"c\": 0.9715},  # 0.2–3.0\n",
    "            \"high\": {\"a\": -0.00168,  \"b\": -0.1329, \"c\": 1.127},  # 3.0–6.0 (example!)\n",
    "            },\n",
    "        11: {\n",
    "            \"low\":  {\"a\": -0.01218, \"b\": -0.07735, \"c\": 0.9603},  # 0.2–3.0\n",
    "            \"high\": {\"a\": 0.09186, \"b\": -0.2137, \"c\": 1.181},  # 3.0–6.0 (example!)\n",
    "            },\n",
    "        }\n",
    "\n",
    "    # Select coefficients based on band\n",
    "\n",
    "    band_coeffs = coeff_map[band]\n",
    "\n",
    "    # Mask low and high range w\n",
    "\n",
    "    w_low = w.where((w >= 0.2) & (w <= 3.0))\n",
    "    w_high = w.where((w >= 3.0) & (w <= 6.0))\n",
    "\n",
    "    if debug:\n",
    "        print(\"Computing tau...\")\n",
    "\n",
    "    # Low-range tau derivation via polynomial\n",
    "\n",
    "    a_low, b_low, c_low = band_coeffs[\"low\"][\"a\"], band_coeffs[\"low\"][\"b\"], band_coeffs[\"low\"][\"c\"]\n",
    "    tau_low = a_low * w_low**2 + b_low * w_low + c_low\n",
    "\n",
    "    # High-range tau derivation via polynomial\n",
    "\n",
    "    a_high, b_high, c_high = band_coeffs[\"high\"][\"a\"], band_coeffs[\"high\"][\"b\"], band_coeffs[\"high\"][\"c\"]\n",
    "    tau_high = a_high * w_high**2 + b_high * w_high + c_high\n",
    "\n",
    "    # Combine results\n",
    "    tau = xr.where(~xr.ufuncs.isnan(tau_low), tau_low, tau_high)\n",
    "\n",
    "    # Only include values in range\n",
    "    tau = tau.where((w >= 0.2) & (w <= 6.0))\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Outputting results...\")\n",
    "    \n",
    "    # Output tau\n",
    "    tau.name = f\"TAU_B{band}\"\n",
    "    tau.attrs[\"units\"] = \"1\"\n",
    "    tau.attrs[\"long_name\"] = f\"Transmittance for Band {band}\"\n",
    "    tau.attrs[\"note\"] = (\n",
    "        \"Derivation is polynomial relationship with water content following Yu et al, 2014\"\n",
    "        \"Polynomial applied piecewise depending on water content range: [0.2-3.0], [3.0-6.0]\"\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        print(tau)\n",
    "\n",
    "    tau = tau.clip(min=0.8, max=1.0)\n",
    "\n",
    "    return tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d053ccc2",
   "metadata": {},
   "source": [
    "## Resampling Tau\n",
    "- Transmissivity according to the polynomials is given for the spatial dimensions of the ERA5 data (~30km)\n",
    "- Thus we need to resample tau to match our Landsat scene\n",
    "- The next block is a function that completes this using nearest neighbour to interpolate the tau values to 30m spatial resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_tau(\n",
    "    tau_input,\n",
    "    resample_match,\n",
    "    out_path,\n",
    "    x_dim = \"longitude\",\n",
    "    y_dim = \"latitude\",\n",
    "    input_crs = \"EPSG:4326\",\n",
    "    debug = False\n",
    "):\n",
    "    tau_data = tau_input.squeeze()\n",
    "    tau_data = tau_data.rio.write_crs(input_crs, inplace = False)\n",
    "    tau_data = tau_data.rename({y_dim: \"y\", x_dim: \"x\"})\n",
    "    tau_data = tau_data.rio.set_spatial_dims(x_dim = \"x\", y_dim = \"y\")\n",
    "    \n",
    "    match_data = rxr.open_rasterio(resample_match).squeeze(\"band\", drop = True)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Tau min / max: {float(np.nanmin(tau_data))}, {float(np.nanmax(tau_data))}\")\n",
    "        print(f\"Tau CRS: {tau_data.rio.crs}\")\n",
    "        print(f\"Match CRS: {match_data.rio.crs}\")\n",
    "        print(f\"Tau shape: {tau_data.shape}, dims: {tau_data.dims}\")\n",
    "        print(f\"Match shape: {match_data.shape}, dims: {match_data.dims}\")\n",
    "    \n",
    "    # Resample\n",
    "    resampled_tau = tau_data.rio.reproject_match(\n",
    "        match_data,\n",
    "        resampling = Resampling.nearest\n",
    "        )\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Tau resampled min / max: {float(np.nanmin(tau_resampled))}, {float(np.nanmax(tau_resampled))}\")\n",
    "        print(f\"Resampled tau shape: {resampled_tau.shape}\")\n",
    "\n",
    "    resampled_tau.rio.to_raster(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68fdf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"data/LANDSAT\")\n",
    "wanted_bands = [10]\n",
    "scenes = collect_scenes(root)\n",
    "\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "\n",
    "    in_dir = next(iter(bmap.values())).parent\n",
    "    \n",
    "    era5_input = in_dir / f\"{sid}_ATM.nc\"\n",
    "    pw, w = derive_water_content(era5_input)\n",
    "\n",
    "    for band in wanted_bands:\n",
    "        tau = derive_tau(w, band = band)\n",
    "        tau_out_path = in_dir / f\"{sid}_B{band}_TAU.tif\"\n",
    "        resample_match = in_dir / f\"{sid}_B{band}_BT.vrt\"\n",
    "\n",
    "        resample_tau(\n",
    "            tau_input = tau,\n",
    "            resample_match = resample_match,\n",
    "            out_path = tau_out_path\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097d898",
   "metadata": {},
   "source": [
    "# LST Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1451f7",
   "metadata": {},
   "source": [
    "By inverting the radiative transfer equation and Planck's law, we can finally derive LST from brightness temperature:\n",
    "\n",
    "$$T_s = \\frac{C_1}{\\lambda_i\\ln(\\frac{C_2}{\\lambda^5_i(B_i(T_i) - L^u_i - \\tau_i(1-\\epsilon_i)L^d_i)/\\tau_i\\epsilon_i} + 1)}$$\n",
    "\n",
    "Where:\n",
    "- $T_s$ is the surface temperature\n",
    "- $C_1$ is 14387.7 $[umK]$\n",
    "- $C_2$ is 1.19104e8 $[W{um}^{4}m^{-2}sr^{-1}]$\n",
    "- $L^u_i$ is upwelling radiance component for the band $i$\n",
    "- $L^d_i$ is downwelling radiance component for the band $i$\n",
    "- $\\tau_i$ is the transmissivity value for the band $i$\n",
    "- $\\epsilon_i$ is the pixel-wise emissivity value for the band $i$\n",
    "- $B_i(T_i)$ is the radiance value at the sensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc3216",
   "metadata": {},
   "source": [
    "Note: Using the RTE with Band 10 is the most accurate!\n",
    "- Yu et al\n",
    "- USGS note known issues with Band 11 calibration / stray-light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h  = 6.62607015e-34   # Planck constant [J*s]\n",
    "c  = 2.99792458e8     # Speed of light [m/s]\n",
    "kB = 1.380649e-23     # Boltzmann constant [J/K]\n",
    "\n",
    "def derive_lst(\n",
    "    bt,\n",
    "    epsilon,\n",
    "    tau,\n",
    "    L_u,\n",
    "    L_d,\n",
    "    wavelength_um\n",
    "):\n",
    "\n",
    "    bt = np.asarray(bt, dtype=float)\n",
    "    epsilon = np.asarray(epsilon, dtype=float)\n",
    "    tau = np.asarray(tau, dtype = float)\n",
    "\n",
    "    lam = float(wavelength_um)\n",
    "\n",
    "    # Convert brightness temp to TOA radiance (B_i(T_i))\n",
    "    BiTi = planck(lam, bt)\n",
    "\n",
    "    # Solve RTE for surface radiance\n",
    "    num = BiTi - L_u - tau * (1 - epsilon) * L_d\n",
    "    den = tau * epsilon\n",
    "    B_surface = np.where(den > 0, num / den, np.nan)\n",
    "\n",
    "    # Invert Planck's law for surface temperature\n",
    "    T_surface = planck_inverse(wavelength_um, B_surface)\n",
    "\n",
    "    return T_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86557141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lst_tif(\n",
    "    bt_input,\n",
    "    epsilon_input,\n",
    "    tau_input,\n",
    "    qa_input,\n",
    "    aoi_path,\n",
    "    out_path,\n",
    "    wavelength_um,\n",
    "    L_u,\n",
    "    L_d,\n",
    "    to_celsius=False,\n",
    "    debug=False,\n",
    "):\n",
    "    # Load inputs\n",
    "    bt = rxr.open_rasterio(bt_input, masked = True).squeeze(\"band\", drop = True)\n",
    "    eps = rxr.open_rasterio(epsilon_input, masked = True).squeeze(\"band\", drop = True)\n",
    "    tau = rxr.open_rasterio(tau_input, masked = True).squeeze(\"band\", drop = True)\n",
    "    qa = rxr.open_rasterio(qa_input, masked = False).squeeze(drop=True)\n",
    "\n",
    "    # Reproject\n",
    "    eps = eps.rio.reproject_match(bt)\n",
    "    tau = tau.rio.reproject_match(bt)\n",
    "    qa = qa.rio.reproject_match(bt)\n",
    "\n",
    "    # Clip\n",
    "    gdf = gpd.read_file(aoi_path)\n",
    "    gdf = gdf.to_crs(bt.rio.crs)\n",
    "    geom = gdf.geometry\n",
    "\n",
    "    bt  = bt.rio.clip(geom, gdf.crs, drop=True)\n",
    "    eps = eps.rio.clip(geom, gdf.crs, drop=True)\n",
    "    tau = tau.rio.clip(geom, gdf.crs, drop=True)\n",
    "    qa = qa.rio.clip(geom, gdf.crs, drop=True)\n",
    "\n",
    "    bt_arr  = bt.values.astype(\"float64\")\n",
    "    eps_arr = eps.values.astype(\"float64\")\n",
    "    tau_arr = tau.values.astype(\"float64\")\n",
    "    qa_arr = qa.values.astype(\"uint8\")\n",
    "\n",
    "    # Define mask\n",
    "    mask_arr = (~np.isfinite(bt_arr)|~np.isfinite(eps_arr)|~np.isfinite(tau_arr))\n",
    "\n",
    "    mask_arr |= (qa_arr != 255)\n",
    "\n",
    "    # Mask out zeros to avoid division by zero in the RTE\n",
    "    eps_arr[eps_arr <= 0] = np.nan\n",
    "    tau_arr[tau_arr <= 0] = np.nan\n",
    "\n",
    "    # Derive LST in K\n",
    "    lst_k = derive_lst(\n",
    "        bt = bt_arr,\n",
    "        epsilon = eps_arr,\n",
    "        tau = tau_arr,\n",
    "        L_u = L_u,\n",
    "        L_d = L_d,\n",
    "        wavelength_um = wavelength_um\n",
    "    )\n",
    "\n",
    "    # Apply mask\n",
    "    lst_k[mask_arr] = np.nan\n",
    "\n",
    "    # Convert to celsius option\n",
    "    if to_celsius:\n",
    "        lst = lst_k - 273.15\n",
    "    else:\n",
    "        lst = lst_k\n",
    "    \n",
    "    # Make data array\n",
    "    lst_da = xr.DataArray(\n",
    "        lst.astype(\"float32\"),\n",
    "        dims = bt.dims,\n",
    "        coords = bt.coords,\n",
    "        name = \"LST\"\n",
    "    )\n",
    "    lst_da = lst_da.rio.write_crs(bt.rio.crs, inplace = True)\n",
    "\n",
    "    nodata_val = -9999.0\n",
    "    lst_da = lst_da.where(np.isfinite(lst_da), nodata_val).astype(\"float32\")\n",
    "    lst_da = lst_da.rio.write_nodata(nodata_val, inplace = True)\n",
    "\n",
    "    # Write tif\n",
    "    lst_da.rio.to_raster(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c7baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('data/LANDSAT/DAY')\n",
    "scenes = collect_scenes(root)\n",
    "wanted_bands = [10]\n",
    "\n",
    "bbox = 'bbox_sm.gpkg'\n",
    "eps_median = 'out/DAY/E_median_sm.tif'\n",
    "srf_input = 'tirs_srs.csv'\n",
    "\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = next(iter(bmap.values())).parent\n",
    "    for band in wanted_bands:\n",
    "        eff_nm = effective_band_wavelength(\n",
    "            srf_input = srf_input,\n",
    "            band = band\n",
    "        )\n",
    "        eff_um = eff_nm / 1000\n",
    "        ld_dat = in_dir / f\"{sid}_B{band}_LD.dat\"\n",
    "        lu_dat = in_dir / f\"{sid}_B{band}_LU.dat\"\n",
    "\n",
    "        ld_agg, lu_agg = rad_srf_weighter(\n",
    "            ld_dat,\n",
    "            lu_dat,\n",
    "            srf_input=srf_input,\n",
    "            band=band\n",
    "        )\n",
    "\n",
    "        L_d = ld_agg * 1000.0\n",
    "        L_u = lu_agg * 1000.0\n",
    "\n",
    "        bt  = in_dir / f\"{sid}_B{band}_BT.vrt\"\n",
    "        tau = in_dir / f\"{sid}_B{band}_TAU.tif\"\n",
    "        qa = in_dir / f\"{sid}_QA.tif\"\n",
    "\n",
    "        out_path = f\"out/DAY/{sid}_B{band}_LSTC.tif\"\n",
    "\n",
    "        build_lst_tif(\n",
    "            bt_input = bt,\n",
    "            epsilon_input = eps_median,\n",
    "            tau_input = tau,\n",
    "            qa_input = qa,\n",
    "            aoi_path = bbox,\n",
    "            out_path = out_path,\n",
    "            wavelength_um = eff_um,\n",
    "            L_u = L_u,\n",
    "            L_d = L_d,\n",
    "            to_celsius = True,\n",
    "            debug = True,\n",
    "        )\n",
    "        \n",
    "        print(f\"-> {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a964a7",
   "metadata": {},
   "source": [
    "## Night\n",
    "- The only difference is we need to input the emissivity from the daytime mosaick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a6b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('data/LANDSAT/NIGHT')\n",
    "scenes = collect_scenes(root)\n",
    "wanted_bands = [10]\n",
    "\n",
    "bbox = 'bbox_sm.gpkg'\n",
    "eps_median = 'out/DAY/E_median_sm.tif'\n",
    "srf_input = 'tirs_srs.csv'\n",
    "\n",
    "for sid, bmap in sorted(scenes.items()):\n",
    "    in_dir = next(iter(bmap.values())).parent\n",
    "    for band in wanted_bands:\n",
    "        eff_nm = effective_band_wavelength(\n",
    "            srf_input = srf_input,\n",
    "            band = band\n",
    "        )\n",
    "        eff_um = eff_nm / 1000\n",
    "        ld_dat = in_dir / f\"{sid}_B{band}_LD.dat\"\n",
    "        lu_dat = in_dir / f\"{sid}_B{band}_LU.dat\"\n",
    "\n",
    "        ld_agg, lu_agg = rad_srf_weighter(\n",
    "            ld_dat,\n",
    "            lu_dat,\n",
    "            srf_input=srf_input,\n",
    "            band=band\n",
    "        )\n",
    "\n",
    "        L_d = ld_agg * 1000.0\n",
    "        L_u = lu_agg * 1000.0\n",
    "\n",
    "        bt  = in_dir / f\"{sid}_B{band}_BT.vrt\"\n",
    "        tau = in_dir / f\"{sid}_B{band}_TAU.tif\"\n",
    "        qa = in_dir / f\"{sid}_QA.tif\"\n",
    "\n",
    "        out_path = f\"out/NIGHT/{sid}_B{band}_LSTC.tif\"\n",
    "\n",
    "        build_lst_tif(\n",
    "            bt_input = bt,\n",
    "            epsilon_input = eps_median,\n",
    "            tau_input = tau,\n",
    "            qa_input = qa,\n",
    "            aoi_path = bbox,\n",
    "            out_path = out_path,\n",
    "            wavelength_um = eff_um,\n",
    "            L_u = L_u,\n",
    "            L_d = L_d,\n",
    "            to_celsius = True,\n",
    "            debug = True,\n",
    "        )\n",
    "\n",
    "        print(f\"-> {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
